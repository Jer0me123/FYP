Add introduction going over what is discussed
\section{Real World Bias}\label{Eval-RealWorldBias}
{
% Prior to discussing the results regarding the generative models, it is crucial to determine the appropriate demographics as they present themselves in the real world, seeing as these models use real-world data to facilitate their training. In accordance with research carried out by the Association of American Medical Colleges (AAMC) \cite{aamc_physicians_sex_2018}, in 2018 only 35.8\% of doctors were female. An adjacent study \cite{oecd_home_2021} conducted globally further supports this with the majority of countries having below 50\% female doctors, with the USA having 37\% as of 2019. Contrarily, the Association of American Medical Colleges \cite{aamc_physicians_sex_race_ethnicity_2018} found that amongst the doctors considered no particular race was underrepresented, with each race having a good gender balance. Finally, \cite{oecd_home_2021} also concluded that a small degree (34\%) of doctors globally are 55 or older as of 2019, but these statistics are rising as years pass.

% In relation to the nurse demographics, \cite{statista_nurses_distribution_2023} denotes how in the regions considered the nurses are predominantly female as of 2018, with the lowest being 65\% female in the Africa region. This is further supported by a more recent study \cite{kharazmi_distribution_2023} denoting how 76.91\% of nurses are female, with the majority of nurses (29.1\%) falling into the 35â€“44 age group globally. Furthermore, \cite{rosseter_nursing_2023} denotes how the majority of the nursing population is predominantly white (80\%) females (88.8\%).

% Taking into consideration the data presented, it is safe to assume that the majority of doctors globally are males younger than 55, whereas the majority of nurses are white females aged 35-44.
}
Prior to carrying out evaluation it is essential to establish a baseline via real-world demographics, seeing as these models rely on real-world data for their training. According to research conducted by the Association of American Medical Colleges (AAMC) \cite{aamc_physicians_sex_2018}, as of 2018, only 35.8\% of doctors were female. Similarly, a global study \cite{oecd_home_2021} further supports this, revealing that in most countries, the proportion of female doctors is below 50\%, with the USA reporting 37\% as of 2019. Contrarily, the Association of American Medical Colleges \cite{aamc2018} found that among the doctors surveyed, 56.2\% of all depictions were white, showcasing an unbalanced gender distribution. Additionally, \cite{oecd_home_2021} also highlights that globally, a minority (34\%) of doctors are aged 55 or older as of 2019, though these figures are gradually increasing over time.

In relation to the nurse demographics, \cite{statista_nurses_distribution_2023} reports that in the regions studied, nurses are predominantly female as of 2018, with the lowest female representation at 65\% in the African region. This trend is reinforced by a more recent study \cite{kharazmi_distribution_2023}, which reveals that 76.91\% of nurses globally are female, with 81.62\% of all nurses younger than 55 % Table 1 of kharazmi_distribution_2023
. Additionally, \cite{rosseter_nursing_2023} highlights that the majority of the nursing population is predominantly white (80\%) and female (88.8\%).

In line with the presented data, it can be assumed that the majority of doctors globally are white, male and younger than 55, this also being the case for nurses save for the dominant gender being female.

\section{Human and AI annotation comparison}\label{Eval-AnnotationBias}
In line with Section \ref{Imp-HumanImageAnnotation} the LAION-400M doctor and nurse image subsets were annotated exposing the innate LAION-400M dataset bias wherein 64.95\% of doctors were labelled as female and 89.69\% of nurses were labelled as female. The majority of depictions were also labelled as white with 62.89\% of all doctors and 61.86\% of all nurses labelled as such. Furthermore the dominant age ranges were 20-29 (25.77\% - Doctor / 38.14\% - Nurse) and 30-39 (51.55\% - Doctor / 48.45\% - Nurse) as seen in Figure \ref{fig:Google-Form-Demographic-Graphs}. 

In comparing these annotations with those carried out by FairFace and DeepFace on the same images it was noted that the FairFace model had minor gender mismatches with 20 total across both image sets with 16 of them being misgendered \textbf{females}. Comparatively the DeepFace model performed significantly worse with 62 gender mismatches all of them being misgendered \textbf{females}. In observing the FairFace racial labels, 67 race mismatches were identified across both image sets, split as follows; 27 white, 13 asian, 12 latino hispanic, 8 black, 4 middle eastern and 3 indian mislabels. DeepFace resulted in less race mismatches, 59 across both image sets with the split being; 19 white, 6 asian, 11 latino hispanic, 13 black, 7 middle eastern and 3 indian. In relation to the age metrics the FairFace model saw 121 age mismatches with 80 of them consisting of the \textbf{30-39} age group being labelled as \textbf{20-29}. The DeepFace model had 89 age mismatches with 32 of which being the \textbf{20-29} age group labelled as \textbf{30-39} and an additional 26 being the \textbf{30-39} age group labelled as \textbf{20-29}.

In light of these results taking the human annotations as a baseline it appears that the FairFace model greatly aligns with said baseline however showcasing a slight tendency to mislabel \textbf{white} and \textbf{female} individuals whilst presenting older individuals as younger. The DeepFace model in comparison appears to stray from said baseline strongly favouring labelling individuals as \textbf{male}, contrarily it showcase a a slightly reduced racial bias to that of the FairFace model  whilst presenting a less predictable age bias than that of its counterpart. In light of this going forward the FairFace model results will be given greater importance given that they align better with the human annotations but also present seemingly predictable bias. 

\begin{figure}[H]
\centering  
\subfigure[Human Annotated Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/GoogleForm/Gender.png}}
\subfigure[Human Annotated Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/GoogleForm/Race.png}}
\subfigure[Human Annotated Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/GoogleForm/Age.png}}
\caption{Google Form Human Annotated Images Demographic Graphs}\label{fig:Google-Form-Demographic-Graphs}
\end{figure}

% Mention the demographics of the responses (briefly as already mentioned in 5.1) 
% Mention agreeableness of annotators using fleiss kappa
% Mention how a singular result for each image was arrived two (majority vote)
% Mention the results that the annotators arrived to and the FairFace/Deepface annotations
% Compare them and outline what bias said annotators had in comparison to human annotations

\section{Bias in LAION-400M Dataset}\label{Eval-Laion400MBias}
In accordance with Figure \ref{fig:LAION-400M-Demographic-Graphs}, image subsets as annotated by the DeepFace model depict a fairly balanced gender representation however the FairFace model presents a biased depiction with both image subsets containing drastically more \textbf{female} depictions. In relation to race both subsets present \textbf{white} as the overly dominant label whereas the dominant age lies between \textbf{20-39} across both models. The correlation results further support the above claims, however the evenness values suggest a relatively even gender split across the board whilst denoting an uneven race and age split.  Observing the prominence metrics in Figure \ref{fig:LAION-400M-Prominence-Graphs} whilst excluding underrepresented labels (indian) outlines an equal prominence across both genders but an unequal race prominence with \textbf{middle eastern} seeming to be far more prominent in the doctor subset whereas \textbf{black} in the nurse subset. A crucial note is the lack of \textbf{indian} depiction across both models and image subsets.

In comparing the results with real life metrics outlined in Section \ref{Eval-RealWorldBias} it can be concluded that the LAION-400M dataset exacerbates the race and age real-world bias as 64.94\% - FairFace / 69.09\% - DeepFace of all depictions are white as to the 56.2\% real world statistic, furthermore 93.77\% - FairFace / 99.74\% - DeepFace of all depcitions are younger than 55 as opposed to the 66\% real world metric. However it appears that the real-world gender metric appears to be reversed whit the majority of doctors depicted being female (given the DeepFace models biased towards labelling images as male) as opposed to the 37\% real world metric. Observing the nurse metrics one can conclude that the gender distribution is slightly more balanced with a reduced female representation (79.22\% - FairFace / 53.25\% - DeepFace) when compared to real life metrics (88.8\%), this trend continues in relation to race with only (59.74\% - FairFace / 64.16\%  - DeepFace) of all individuals being white as opposed to the 80\% globally. Finally, (93.77\% - FairFace / 99.74\% - DeepFace) of nurse depictions are younger than 55 as opposed to the 81.62\% real world metric. 

\begin{figure}[H]
\centering  
\subfigure[FairFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/LAION/Gender.png}}
\subfigure[FairFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/LAION/Race.png}}
\subfigure[FairFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/LAION/Age.png}}

\subfigure[DeepFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/LAION/Gender.png}}
\subfigure[DeepFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/LAION/Race.png}}
\subfigure[DeepFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/LAION/Age.png}}
\caption{LAION-400M Demographic Graphs}\label{fig:LAION-400M-Demographic-Graphs}
\end{figure}

\begin{figure}[H]
\centering  
\subfigure[FairFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/LAION/Area - Gender.png}}
\subfigure[FairFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/LAION/Center - Gender.png}}
\subfigure[FairFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/LAION/Area - Race.png}}
\subfigure[FairFace Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/LAION/Center - Race.png}}

\subfigure[DeepFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/LAION/Area - Gender.png}}
\subfigure[DeepFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/LAION/Center - Gender.png}}
\subfigure[DeepFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/LAION/Area - Race.png}}
\subfigure[DeepFace  Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/LAION/Center - Race.png}}
\caption{LAION-400M Prominence Graphs}\label{fig:LAION-400M-Prominence-Graphs}
\end{figure}

% Mention how the subsets where annotated 
% Mention the results/metrics relevant to each of the subsets 
% Compare these results to real life data/metrics 
% Conclude on the bias present in the Laion-400M dataset for each label

\section{Stable Diffusion result analysis}\label{Eval-StableDiffusion}

In accordance with Figure \ref{fig:StableDiffusion-Demographic-Graphs}, Stable Diffusion depicts a skewed gender representation with an overwhelming depiction of \textbf{male} doctors (88.31\% - FairFace / 89.61\% - DeepFace) and \textbf{female} nurses (96.62\% - FairFace / 90.65\% - DeepFace). The joint subset appears balanced, most likely due to the doctors depicted being predominantly male whereas, the nurses female thereby cancelling out the bias. Observing the race graph it is clear that the \textbf{white} label is far more prominent than the rest, the same can be said for the \textbf{20-29} and \textbf{30-39} age range labels. The correlation and evenness results, depict the same image as outlined prior with gender, race and age all having a dominant label save for gender in the joint subset. The prominence graphs in Figure \ref{fig:Stable-Diffusion-Prominence-Graphs} denote an equal level of prominence across both genders in all image subsets, however the same is not the case for race as \textbf{asian} individuals appear to be more prominent overall although cases do exist where this is not the case.

In comparing the results with the LAION-400M metrics outlined in Section \ref{Eval-Laion400MBias} it can be concluded that the Stable Diffusion model exacerbates the innate dataset bias with the majority of doctors (88.31\% - FairFace / 89.61\% - DeepFace) depicted as male whereas the majority of nurses (96.62\% - FairFace / 90.65\% - DeepFace) as female. Furthermore, the same can be said in relation to race and age having \textbf{white} [(71.17\% - FairFace / 78.18\% - DeepFace) - Doctor /(57.4\% - FairFace / 68.05\% - DeepFace)] be the dominant race and the majority of depiction younger than 55 [(96.88\% - FairFace / 100\% - DeepFace) - Doctor /(100\% - FairFace / 100\% - DeepFace)]. Given this comparison it can be concluded that the Stable Diffusion model contains increased gender, racial and age bias than the innate bias in the LAION-400M training dataset.

\begin{figure}[H]
\centering  
\subfigure[FairFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/StableDiffusion/Gender.png}}
\subfigure[FairFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/StableDiffusion/Race.png}}
\subfigure[FairFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/StableDiffusion/Age.png}}

\subfigure[DeepFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/StableDiffusion/Gender.png}}
\subfigure[DeepFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/StableDiffusion/Race.png}}
\subfigure[DeepFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/StableDiffusion/Age.png}}
\caption{StableDiffusion Demographic Graphs}\label{fig:StableDiffusion-Demographic-Graphs}
\end{figure}

\begin{figure}[H]
\centering  
\subfigure[FairFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/StableDiffusion/Area - Gender.png}}
\subfigure[FairFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/StableDiffusion/Center - Gender.png}}
\subfigure[FairFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/StableDiffusion/Area - Race.png}}
\subfigure[FairFace Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/StableDiffusion/Center - Race.png}}

\subfigure[DeepFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/StableDiffusion/Area - Gender.png}}
\subfigure[DeepFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/StableDiffusion/Center - Gender.png}}
\subfigure[DeepFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/StableDiffusion/Area - Race.png}}
\subfigure[DeepFace  Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/StableDiffusion/Center - Race.png}}
\caption{Stable Diffusion Prominence Graphs}\label{fig:Stable-Diffusion-Prominence-Graphs}
\end{figure}

\section{Dall-E result analysis}\label{Eval-Dall-E}

In accordance with Figure \ref{fig:Dall-E-Demographic-Graphs}, Dall-E depicts a balanced gender distribution save for the Doctor subset wherein the majority (72.21\% - FairFace / 69.09\% - DeepFace) of depictions are \textbf{female}. Contrarily, the majority of the races are sufficiently represented across all three subsets with \textbf{asian} and \textbf{indian} being the most prominent overall. Contrarily, all image subsets fall within the \textbf{10-39} age range however given the years required to become a certified doctor or nurse the \textbf{10-19} age range appears likely to be a miss-classification on behalf of the FairFace model likely due to how Dall-E generates images. Considering the correlation and evenness results depicted in Tables \ref{} \ref{} they support the claims made prior of a balanced gender and race representation also hinting at an even gender split within the doctor subset. The prominence metrics in Figure \ref{fig:Dall-E-Prominence-Graphs} denote that both genders are relatively equally prominent with \textbf{male} being slightly more prominent overall. The same can be attributed to the races however certain races appear to be more prominent depending on the image subset.

Given that the Dall-E's training dataset is not publicly available comparison was carried out primarily with the real world metrics as opposed to the LAION-400M dataset. In light of this it is clear that the Dall-E model was primarily designed with diversity in mind, given that the percentage of male doctors is at (27.79\% - FairFace / 30.91\% - DeepFace) as opposed to the 63\% globally, whereas the depiction of female nurses is at (56.1\% - FairFace / 53.51\% - DeepFace) as opposed to the 88.8\% globally. Furthermore, the model presents a wider range of races as opposed to real world metrics wherein majority are white (56.2\% - Doctor / 80\% - Nurse) however their appears to be a slight bias towards depicting asians and indians with their percentages varying between (17.66\% - 56.88\%) and (28\% - 52.21\%) respectively. Contrarily, it is evident that the Dall-E model depicts the innate bias present globally where the majority of doctors and nurses are younger than 55 with all of its depictions falling within this age range. Given, this comparison it clear that such a model is far less biased then its counterparts however it is important to note that such results are not achieved solely via the model rather Dall-E utilises a separate prompt refining model which for instace can convert a simple prompt "a picture of a doctor facing forward" into "Visualize an image showing a South-Asian female doctor standing confidently and facing forward. She is wearing a traditional white doctor's coat, with a stethoscope hung around her neck. Her hair is neatly tied into a bun, her eyes are focused, showcasing an aura of professionalism and dedication. The background is of a well-lit, clean medical clinic indicating a regular workday." as denoted in \ref{dalle3-prompt-guide}. This begs the question then of whether the reduction in bias and increased diversity it due to how the model was trained and constructed or whether it is solely due to the prompt refining model 

\begin{figure}[H]
\centering  
\subfigure[FairFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Dall-E/Gender.png}}
\subfigure[FairFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Dall-E/Race.png}}
\subfigure[FairFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Dall-E/Age.png}}

\subfigure[DeepFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Dall-E/Gender.png}}
\subfigure[DeepFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Dall-E/Race.png}}
\subfigure[DeepFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Dall-E/Age.png}}
\caption{Dall-E Demographic Graphs}\label{fig:Dall-E-Demographic-Graphs}
\end{figure}

\begin{figure}[H]
\centering  
\subfigure[FairFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Dall-E/Area - Gender.png}}
\subfigure[FairFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Dall-E/Center - Gender.png}}
\subfigure[FairFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Dall-E/Area - Race.png}}
\subfigure[FairFace Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Dall-E/Center - Race.png}}

\subfigure[DeepFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Dall-E/Area - Gender.png}}
\subfigure[DeepFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Dall-E/Center - Gender.png}}
\subfigure[DeepFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Dall-E/Area - Race.png}}
\subfigure[DeepFace  Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Dall-E/Center - Race.png}}
\caption{Dall-E Prominence Graphs}\label{fig:Dall-E-Prominence-Graphs}
\end{figure}

{
% The doctor images generated via Dall-E consisted of 69.09\% - 72.21\% \textbf{female} with decent racial diversity throughout as seen in Figure \ref{}. However it seems that Dall-E is disposed to depicting younger individuals, with the age groups primarily depicted being 20-39 and 10-29 for DeepFace and FairFace respectively with a large majority falling under the 20-29 age range in both instances. Furthermore, the common positive correlations between both annotation techniques being \textbf{female, asian, indian, 20-29} promote the idea of the model favouring females whilst also tending to focus on a particular demographic. Contrarily, the evenness values denoted in Tables \ref{tab:doctor-shannon-simpson-fairFace} and \ref{tab:doctor-shannon-simpson-deepFace} depict a fairly even distribution of gender and races although the former seeming to be an outlier as denoted by the overall count and positive correlation results. Moving onwards to the area and center distance metrics their appears to be no major discrepancy between the distance from centers across genders however it seems that females tend to occupy less space in the image as denoted by the 77.96\% and 82.63\% in the FairFace model and 78.11\% and 81.02\% in the DeepFace model. Observing these results from a racial perspective depicts a fairly balanced picture with no particular race showcasing significantly distinct results save for black in relation to the center distance within the DeepFace annotation subset however this is most likely due to outliers as the remaining races show no significant difference and this same occurrence does not present itself in the FairFace results.

% The nurse image subset surprisingly depicts a balanced gender split with the FairFace results being split 43.9\% (M) 56.1\% (F) and the Deepface result being 46.49\% (M) 53.51\% (F). Furthermore, all races seem to have adequate representation with asian, indian and latino hispanic being the most prominent races across both instances. Furthermore, the age ranges follow a similar depiction similar to that of the doctor subset with FairFace mostly detecting ages between 10-29 and DeepFace ages 20-39. Taking a look at the positive correlations they coincide with the dominant labels outlined with the evenness measure depicting strong evenness in terms of both gender and race which holds true across both annotation models. Finally, their does not appear to be a major discrepancy between the area and center distance across both gender and race with all depictions being fairly central lending to a high degree of person prominence, however black individuals do appear to be the least prominent with them generally taking up less of the image (77.68\%) and being furthest away (51.81px) across both annotation techniques.

% Looking at the doctor and nurse subset the gender distribution is balanced with FairFace having a 52\% (M) to 47.4\% (F) split whilst DeepFace had 56.36\% (M) to 43.63\% (F). Furthermore the balanced depiction seems to remain constant across the races however the middle eastern race does appear to be lacking in representation (6.1\%) when compared to the rest of the races in the FairFace annotations. Similar to prior observation made regarding the age groups the primary ages depicted across both annotation models are 10-39, with 20-29 being the most prominent age in FairFace whilst 30-39 in DeepFace. Observing the positive correlations across both models \textbf{male, asian, white, indian, 10-19, 20-29, 30-39} further supports the prior claims. Furthermore, the evenness values in Tables \ref{tab:doctor-nurse-shannon-simpson-fairFace} and \ref{tab:doctor-nurse-shannon-simpson-deepFace} accurately represent the data with high evenness across gender and race whilst being less so in terms of age. Finally, both individuals in the image appear to be equally prominent however taking up less image space overall than the depictions presented in the doctor and nurse subsets discussed prior. 

% Compare results to the LAION400M and real world

% Mention the changing of the prompts 
}

% Mention the results /metrics achieved 
% Compare these results to real life data/metrics 
% Compare these results to that present in the LAION-400M dataset
% Mention the change in the prompt which it carries out
% Conclude on the bias present

\section{Midjourney result analysis}\label{Eval-Midjourney}

In accordance with Figure \ref{fig:Midjourney-Demographic-Graphs}, Midjourney depicts a skewed gender distribution with the majority (88.31\% - FairFace / 91.69\% - DeepFace) of doctors being \textbf{male} whereas the majority (97.14\% - FairFace / 93.77\% - DeepFace) of nurses being \textbf{female}. This in turn results in a balanced Doctor and Nurse subset for the same reason as discussed in Section \ref{Eval-StableDiffusion}. The races depicted predominately include \textbf{white}, \textbf{black} and \textbf{latino hispanic} individuals across all three image subsets. Furthermore, although their appear to be depictions of older individuals within all three image subsets the dominant age range remains consistent with previous observations wherein \textbf{20-29} and \textbf{30-39} were dominant. The correlation metrics backup the claims made above whilst the evenness results denote a relatively uneven race split with the remaining results enforcing the claims presented prior. In relation to the prominence metrics in Figure \ref{fig:Midjourney-Demographic-Graphs} both genders along with all the races are depicted in a relatively equal degree of prominence save for minor cases in which the race in question has minimal representation such as \textbf{indian} within the DeepFace annotations. 

In comparing the Midjourney model results to that of the real world the abundant gender bias is evident with major portion of doctors being male and nurses female going even beyond the demographics observed globally. Furthermore, it appears that although white is still the dominant race it appears less so than observed globally with the Doctor subset having (34\% - FairFace / 40\% - DeepFace) as opposed to 56.2\% observed globally and nurses having (45\% - FairFace / 57.92\% - DeepFace) as opposed to the 80\% observed globally. In relation to the age demographics it appears that although their are depictions of individuals older than 55 the majority still fall below that age. This results in a model which portrays sever gender bias, an increase in age bias when compared to real world metrics and reduced racial bias. 

\begin{figure}[H]
\centering  
\subfigure[FairFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Midjourney/Gender.png}}
\subfigure[FairFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Midjourney/Race.png}}
\subfigure[FairFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Midjourney/Age.png}}

\subfigure[DeepFace Gender Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Midjourney/Gender.png}}
\subfigure[DeepFace Race Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Midjourney/Race.png}}
\subfigure[DeepFace Age Graph]{\includegraphics[width=0.32\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Midjourney/Age.png}}
\caption{Midjourney Demographic Graphs}\label{fig:Midjourney-Demographic-Graphs}
\end{figure}

\begin{figure}[H]
\centering  
\subfigure[FairFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Midjourney/Area - Gender.png}}
\subfigure[FairFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Midjourney/Center - Gender.png}}
\subfigure[FairFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Midjourney/Area - Race.png}}
\subfigure[FairFace Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/FairFaceGraphs/Midjourney/Center - Race.png}}

\subfigure[DeepFace Area-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Midjourney/Area - Gender.png}}
\subfigure[DeepFace Center-Gender Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Midjourney/Center - Gender.png}}
\subfigure[DeepFace Area-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Midjourney/Area - Race.png}}
\subfigure[DeepFace  Center-Race Graph]{\includegraphics[width=0.24\textwidth]{FYP - Thesis/Images/DeepFaceGraphs/Midjourney/Center - Race.png}}
\caption{Midjourney Prominence Graphs}\label{fig:Midjourney-Prominence-Graphs}
\end{figure}
% Mention the results /metrics achieved 
% Compare these results to real life data/metrics 
% Compare these results to that present in the LAION-400M dataset
% Conclude on the bias present

\section{Conclusion}
Determine which model has the least bias and is overall the best to use in terms of bias, image quality and so on.

% % Doctor-385-Area/Distance
% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline 
% Races & Asian & Black & Indian & Hispanic & Middle Eastern & White\\
% \hline
% Area (SD) & 92.52 & 84.99 & 65.45 & 79.29 & 70.24 & 74.57\\
% Distance (SD) & 17.03 & 27.56 & 30.27 & 38.01 & 38.06 & 32.48\\
% \hline
% Area (Dall-E) & 81.21 & 79.89 & 78.03 & 82.63 & 79.65 & 74.77\\
% Distance (Dall-E) & 28.09 & 32.01 & 31.38 & 35.44 & 48.09 & 30.02\\
% \hline
% Area (MidJourney) & 80.4 & 78.72 & 85.94 & 85.06 & 78.42 & 81.27\\
% Distance (MidJourney) & 38.95 & 42.65 & 31.14 & 32.02 & 41 & 34\\
% \hline
% \end{tabular}
% \caption{Doctor-Race-FairFace}
% \label{tab:doctor-race-fairFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|}
% \hline 
% Gender & Male & Female\\ 
% \hline
% Area (SD) & 75.99 & 75.53\\
% Distance (SD) & 32.02 & 36.06\\
% \hline
% Area (Dall-E) & 82.63 & 77.96\\
% Distance (Dall-E) & 31 & 33.36\\
% \hline
% Area (MidJourney) & 81.68 & 81\\
% Distance (MidJourney) & 35.93 & 44.94\\
% \hline
% \end{tabular}
% \caption{Doctor-Gender-FairFace}
% \label{tab:doctor-gender-fairFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline 
% Races & Asian & Black & Indian & Hispanic & Middle Eastern & White\\ 
% \hline
% Area (SD) & 88.91 & 84.99 & 64.14 & 74.59 & 69.04 & 74.68\\
% Distance (SD) & 16.03 & 26.36 & 91.01 & 37.01 & 50.76 & 32.02\\
% \hline
% Area (Dall-E) & 77.3 & 80.08 & 79.78 & 78.03 & 83.14 & 76.27\\
% Distance (Dall-E) & 30.73 & 72.11 & 29.65 & 35.69 & 34.03 & 31.0\\
% \hline
% Area (MidJourney) & 79.86 & 76.23 & 82.44 & 85.94 & 83.5 & 82.72\\
% Distance (MidJourney) & 37.05 & 45.95 & 49.4 & 33.97 & 29.53 & 32.29\\
% \hline
% \end{tabular}
% \caption{Doctor-Race-DeepFace}
% \label{tab:doctor-race-deepFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|}
% \hline 
% Gender & Male & Female\\ 
% \hline
% Area (SD) & 76.01 & 75.24\\
% Distance (SD) & 32.02 & 35.76\\
% \hline
% Area (Dall-E) & 81.02 & 78.11\\
% Distance (Dall-E) & 31 & 33.36\\
% \hline
% Area (MidJourney) & 81.68 & 81.49\\
% Distance (MidJourney) & 36.12 & 44.48\\
% \hline
% \end{tabular}
% \caption{Doctor-Gender-DeepFace}
% \label{tab:doctor-gender-deepFace}
% \end{table}

% Nurse-385-Area/Distance
% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline 
% Races & Asian & Black & Indian & Hispanic & Middle Eastern & White\\
% \hline
% Area (SD) & 99.22 & 90.64 & 67.84 & 71.97 & 81.71 & 73.2\\
% Distance (SD) & 1.41 & 18.0 & 58.46 & 36.21 & 45.01 & 32.28\\
% \hline
% Area (Dall-E) & 79.72 & 77.99 & 83.06 & 87.36 & 85.93 & 85.45\\
% Distance (Dall-E) & 32.39 & 41.61 & 27.07 & 25.21 & 22.69 & 18.03\\
% \hline
% Area (MidJourney) & 78.82 & 81.09 & 83.57 & 84.46 & 80.81 & 80.69\\
% Distance (MidJourney) & 45.28 & 43.78 & 43.86 & 32.0 & 28.18 & 38.51\\
% \hline
% \end{tabular}
% \caption{Nurse-Race-FairFace}
% \label{tab:nurse-race-fairFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|}
% \hline 
% Gender & Male & Female\\ 
% \hline
% Area (SD) & 78.02 & 75.44\\
% Distance (SD) & 26.68 & 28.94\\
% \hline
% Area (Dall-E) &83.37 & 81.94\\
% Distance (Dall-E) & 23.43 & 29.51\\
% \hline
% Area (MidJourney) & 83.5 & 81.47\\
% Distance (MidJourney) & 47.17 & 39.16\\
% \hline
% \end{tabular}
% \caption{Nurse-Gender-FairFace}
% \label{tab:nurse-gender-fairFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline 
% Races & Asian & Black & Indian & Hispanic & Middle Eastern & White\\ 
% \hline
% Area (SD) & 59.73 & 86.0 & n/a & 69.5 & 97.47 & 74.06\\
% Distance (SD) & 34.01 & 20.62 & n/a & 29.26 & 2.0 & 32.17\\
% \hline
% Area (Dall-E) & 80.86 & 77.36 & 83.81 & 89.11 & 79.93 & 83.12\\
% Distance (Dall-E) & 36.0 & 62.01 & 23.22 & 21.02 & 23.26 & 20.25\\
% \hline
% Area (MidJourney) & 78.75 & 80.75 & 93.0 & 83.37 & 74.03 & 83.42\\
% Distance (MidJourney) & 46.07 & 44.1 & 12.17 & 38.63 & 31.89 & 36.77\\
% \hline
% \end{tabular}
% \caption{Nurse-Race-DeepFace}
% \label{tab:nurse-race-deepFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|}
% \hline 
% Gender & Male & Female\\ 
% \hline
% Area (SD) & 75.56 & 75.44\\
% Distance (SD) & 34.01 & 28.23\\
% \hline
% Area (Dall-E) & 82.94 & 82.09\\
% Distance (Dall-E) & 23.54 & 29.67\\
% \hline
% Area (MidJourney) & 84.0 & 81.44\\
% Distance (MidJourney) & 44.06 & 37.66\\
% \hline
% \end{tabular}
% \caption{Nurse-Gender-DeepFace}
% \label{tab:nurse-gender-deepFace}
% \end{table}

% Doctor-Nurse-385-Area/Distance
% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline 
% Races & Asian & Black & Indian & Hispanic & Middle Eastern & White\\
% \hline
% Area (SD) & 45.81 & 48.22 & 41.27 & 39.04 & 40.49 & 42.4\\
% Distance (SD) & 110.65 & 114.27 & 115.43 & 122.98 & 118.94 & 118.17\\
% \hline
% Area (Dall-E) & 47.79 & 49.94 & 54.23 & 49.37 & 49.1 & 55.45\\
% Distance (Dall-E) & 240.0 & 239.55 & 219.08 & 244.0 & 242.1 & 218.42\\
% \hline
% Area (MidJourney) & 45.04 & 46.44 & 48.41 & 46.86 & 48.19 & 45.69\\
% Distance (MidJourney) & 229.12 & 221.66 & 222.53 & 228.6 & 223.36 & 233.6\\
% \hline
% \end{tabular}
% \caption{Doctor-Nurse-Race-FairFace}
% \label{tab:doctor-nurse-race-fairFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|}
% \hline 
% Gender & Male & Female\\ 
% \hline
% Area (SD) & 45.14 & 39.96\\
% Distance (SD) & 117.24 & 118.26\\
% \hline
% Area (Dall-E) & 55.52 & 46.29\\
% Distance (Dall-E) & 217.08 & 249.27\\
% \hline
% Area (MidJourney) & 49.84 & 41.92\\
% Distance (MidJourney) & 218.9 & 243.72\\
% \hline
% \end{tabular}
% \caption{Doctor-Nurse-Gender-FairFace}
% \label{tab:doctor-nurse-gender-fairFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline 
% Races & Asian & Black & Indian & Hispanic & Middle Eastern & White\\ 
% \hline
% Area (SD) & 37.09 & 48.79 & 52.2 & 39.04 & 43.1 & 42.3\\
% Distance (SD) & 118.85 & 114.0 & 64.56 & 122.98 & 119.3 & 117.48\\
% \hline
% Area (Dall-E) & 47.42 & 50.36 & 55.97 & 49.66 & 54.8 & 54.63\\
% Distance (Dall-E) & 240.73 & 235.0 & 216.53 & 242.9 & 221.11 & 218.28\\
% \hline
% Area (MidJourney) & 45.9 & 46.9 & 39.16 & 45.72 & 49.36 & 46.02\\
% Distance (MidJourney) & 227.61 & 222.75 & 210.3 & 221.46 & 227.27 & 230.69\\
% \hline
% \end{tabular}
% \caption{Doctor-Nurse-Race-DeepFace}
% \label{tab:doctor-nurse-race-deepFace}
% \end{table}

% \begin{table}[h]
% \centering
% \begin{tabular}{|c|c|c|}
% \hline 
% Gender & Male & Female\\ 
% \hline
% Area (SD) & 43.25 & 41.12\\
% Distance (SD) & 116.42 & 119.82\\
% \hline
% Area (Dall-E) & 54.85 & 46.97\\
% Distance (Dall-E) & 219.04 & 246.26\\
% \hline
% Area (MidJourney) & 49.59 & 41.84\\
% Distance (MidJourney) & 219.92 & 243.72\\
% \hline
% \end{tabular}
% \caption{Doctor-Nurse-Gender-DeepFace}
% \label{tab:doctor-nurse-gender-deepFace}
% \end{table}

% Doctor-Shannon-Simpson-FairFace
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Attribute & Gender & Race & Age \\
\hline
Shannon Entropy (LAION-400M) & 0.674  &  1.141  &  1.026 \\
Simpson Index (LAION-400M) & 1.9287 &  2.199  &  1.835 \\
Shannon Evenness (LAION-400M) & 0.972  &  0.637  &  0.467 \\
Simpson Evenness (LAION-400M) & 0.963  &  0.366  &  0.204 \\
\hline
Shannon Entropy (SD) & 0.361 & 0.997 & 1.102 \\
Simpson Index (SD) & 1.260 & 1.887 & 2.514 \\
Shannon Evenness (SD) & 0.52 & 0.556 & 0.502 \\
Simpson Evenness (SD) & 0.63 & 0.315 & 0.279 \\
\hline
Shannon Entropy (Dall-E) & 0.591 & 1.421 & 0.825 \\
Simpson Index (Dall-E) & 1.67 & 3.059 & 2.015 \\
Shannon Evenness (Dall-E) & 0.853 & 0.793 & 0.375 \\
Simpson Evenness (Dall-E) & 0.835 & 0.510 & 0.224 \\
\hline
Shannon Entropy (MidJourney) & 0.361  &  1.64  &  1.491 \\
Simpson Index (MidJourney) & 1.26  &  4.529  &  3.338 \\
Shannon Evenness (MidJourney) & 0.52  &  0.915  &  0.678 \\
Simpson Evenness (MidJourney) & 0.63  &  0.755  &  0.371 \\
\hline
\end{tabular}
\caption{Doctor-Shannon-Simpson-FairFace}
\label{tab:doctor-shannon-simpson-fairFace}
\end{table}

% Nurse-Shannon-Simpson-FairFace
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Attribute & Gender & Race & Age \\
\hline
Shannon Entropy (LAION-400M) & 0.511  &  1.239  &  1.108 \\
Simpson Index (LAION-400M) & 1.491  &  2.5  &  2.013 \\
Shannon Evenness (LAION-400M) & 0.737  &  0.692  &  0.504 \\
Simpson Evenness (LAION-400M) & 0.745  &  0.417  &  0.224 \\
\hline
Shannon Entropy (SD) & 0.148  &  1.056  &  0.21 \\
Simpson Index (SD) & 1.07  &  2.418  &  1.088 \\
Shannon Evenness (SD) & 0.213  &  0.59  &  0.095 \\
Simpson Evenness (SD) & 0.535  &  0.403  &  0.121 \\
\hline
Shannon Entropy (Dall-E) & 0.686  &  1.656  &  0.817 \\
Simpson Index (Dall-E) & 1.971  &  4.666  &  1.992 \\
Shannon Evenness (Dall-E) & 0.989  &  0.924  &  0.372 \\
Simpson Evenness (Dall-E) & 0.985  &  0.778  &  0.221 \\
\hline
Shannon Entropy (MidJourney) & 0.13  &  1.429  &  0.652 \\
Simpson Index (MidJourney) & 1.059  &  3.381  &  1.506 \\
Shannon Evenness (MidJourney) & 0.187  &  0.797  &  0.297 \\
Simpson Evenness (MidJourney) & 0.529  &  0.564  &  0.167 \\
\hline
\end{tabular}
\caption{Nurse-Shannon-Simpson-FairFace}
\label{tab:nurse-shannon-simpson-fairFace}
\end{table}

% Doctor-Nurse-Shannon-Simpson-FairFace
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline 
Attribute & Gender & Race & Age\\
\hline
Shannon Entropy (SD) & 0.681  &  0.964  &  1.005 \\
Simpson Index (SD) & 1.953  &  1.854  &  2.076 \\
Shannon Evenness (SD) & 0.982  &  0.538  &  0.457 \\
Simpson Evenness (SD) & 0.976  &  0.309  &  0.231 \\
\hline
Shannon Entropy (Dall-E) & 0.692  &  1.671  &  0.838 \\
Simpson Index (Dall-E) & 1.995  &  4.857  &  1.859 \\
Shannon Evenness (Dall-E) & 0.998  &  0.932  &  0.381 \\
Simpson Evenness (Dall-E) & 0.997  &  0.809  &  0.207 \\
\hline
Shannon Entropy (MidJourney) & 0.693  &  1.553  &  1.098 \\
Simpson Index (MidJourney) & 2.0  &  3.96  &  2.244 \\
Shannon Evenness (MidJourney) & 1.0  &  0.867  &  0.5 \\
Simpson Evenness (MidJourney) & 1.0  &  0.66  &  0.249 \\
\hline
\end{tabular}
\caption{Doctor-Nurse-Shannon-Simpson-FairFace}
\label{tab:doctor-nurse-shannon-simpson-fairFace}
\end{table}

% Doctor-Shannon-Simpson-DeepFace
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline 
Attribute & Gender & Race & Age\\
\hline
Shannon Entropy (LAION-400M) & 0.677  &  0.985  &  0.804 \\
Simpson Index (LAION-400M) & 1.938  &  1.944  &  1.921 \\
Shannon Evenness (LAION-400M) & 0.977  &  0.55  &  0.366 \\
Simpson Evenness (LAION-400M) & 0.969  &  0.324  &  0.214 \\
\hline
Shannon Entropy (SD) & 0.334  &  0.814  &  0.757 \\
Simpson Index (SD) & 1.229  &  1.596  &  1.891 \\
Shannon Evenness (SD) & 0.481  &  0.454  &  0.344 \\
Simpson Evenness (SD) & 0.614  &  0.266  &  0.21 \\
\hline 
Shannon Entropy (Dall-E) & 0.618  &  1.682  &  0.747 \\
Simpson Index (Dall-E) & 1.746  &  5.021  &  2.028 \\
Shannon Evenness (Dall-E) & 0.892  &  0.939  &  0.34 \\
Simpson Evenness (Dall-E) & 0.873  &  0.837  &  0.225 \\
\hline 
Shannon Entropy (MidJourney) & 0.286  &  1.516  &  1.194 \\
Simpson Index (MidJourney) & 1.18  &  3.945  &  2.944 \\
Shannon Evenness (MidJourney) & 0.413  &  0.846  &  0.543 \\
Simpson Evenness (MidJourney) & 0.59  &  0.657  &  0.327 \\
\hline
\end{tabular}
\caption{Doctor-Shannon-Simpson-DeepFace}
\label{tab:doctor-shannon-simpson-deepFace}
\end{table}

% Nurse-Shannon-Simpson-DeepFace
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline 
Attribute & Gender & Race & Age\\
\hline
Shannon Entropy (LAION-400M) & 0.691  &  1.068  &  0.839 \\
Simpson Index (LAION-400M) & 1.992  &  2.17  &  2.023 \\
Shannon Evenness (LAION-400M) & 0.997  &  0.596  &  0.382 \\
Simpson Evenness (LAION-400M) & 0.996  &  0.362  &  0.225 \\
\hline
Shannon Entropy (SD) & 0.311  &  0.953  &  0.693 \\
Simpson Index (SD) & 1.204  &  1.982  &  1.831 \\
Shannon Evenness (SD) & 0.448  &  0.532  &  0.315 \\
Simpson Evenness (SD) & 0.602  &  0.33  &  0.203 \\
\hline 
Shannon Entropy (Dall-E) & 0.691  &  1.649  &  0.708 \\
Simpson Index (Dall-E) & 1.99  &  4.533  &  1.964 \\
Shannon Evenness (Dall-E) & 0.996  &  0.92  &  0.322 \\
Simpson Evenness (Dall-E) & 0.995  &  0.756  &  0.218 \\
\hline 
Shannon Entropy (MidJourney) & 0.233  &  1.186  &  0.785 \\
Simpson Index (MidJourney) & 1.132  &  2.537  &  2.075 \\
Shannon Evenness (MidJourney) & 0.337  &  0.662  &  0.357 \\
Simpson Evenness (MidJourney) & 0.566  &  0.423  &  0.231 \\
\hline
\end{tabular}
\caption{Nurse-Shannon-Simpson-DeepFace}
\label{tab:nurse-shannon-simpson-deepFace}
\end{table}

% Doctor-Nurse-Shannon-Simpson-DeepFace
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline 
Attribute & Gender & Race & Age\\
\hline
Shannon Entropy (SD) & 0.692  &  0.856  &  0.782 \\
Simpson Index (SD) & 1.997  &  1.659  &  1.822 \\
Shannon Evenness (SD) & 0.999  &  0.478  &  0.356 \\
Simpson Evenness (SD) & 0.998  &  0.276  &  0.202 \\
\hline 
Shannon Entropy (Dall-E) & 0.685  &  1.736  &  0.726 \\
Simpson Index (Dall-E) & 1.968  &  5.381  &  1.911 \\
Shannon Evenness (Dall-E) & 0.988  &  0.969  &  0.33 \\
Simpson Evenness (Dall-E) & 0.984  &  0.897  &  0.212 \\
\hline 
Shannon Entropy (MidJourney) & 0.687  &  1.267  &  0.976 \\
Simpson Index (MidJourney) & 1.978  &  2.58  &  2.258 \\
Shannon Evenness (MidJourney) & 0.992  &  0.707  &  0.444 \\
Simpson Evenness (MidJourney) & 0.989  &  0.43  &  0.251 \\
\hline
\end{tabular}
\caption{Doctor-Nurse-Shannon-Simpson-DeepFace}
\label{tab:doctor-nurse-shannon-simpson-deepFace}
\end{table}


\section{LAION-400M OLD}
Two subsets of \textbf{385} randomly selected LAION-400M images, labelled as \textit{doctor} or \textit{nurse} were annotated using DeepFace and FairFace models in line with chapters 4 and 5. 

The doctor subset appears to be fairly evenly split in relation to gender with the FairFace results denoting more woman where the opposite holds true in relation to the DeepFace results as seen in Figure \ref{fig:LAION-Gender-Graphs}. Furthermore, both models denote an abundance of \textbf{white} individuals with 64.93\% (FairFace) and 69.09\% (DeepFace) of all depictions labelled as \textbf{white}. With regards to age both models outline that the majority of all depictions, 84.42\% (FairFace) and 94.29\% (DeepFace) fall within the \textbf{20-29} and \textbf{30-39} age ranges. This is further supported via the positive correlations with the aforementioned labels. The evenness results appear to depict a similar picture with the gender values hinting at high evenness whilst the race and age values hinting at a dominant label, as seen in Tables \ref{tab:doctor-shannon-simpson-fairFace} and \ref{tab:doctor-shannon-simpson-deepFace}. Furthermore, individuals seem to be equally prominent within their respective images across both genders and races, however the latter does hint at the presence of some bias in relation to the prominence of certain races however due to the reduced representation of said races it is unclear as to whether this bias is truly present or simply a result of the reduced representation. 

The nurse subset seems to be predominantly composed of \textbf{female} depictions with 79.22\% (FairFace) and 53.25\% (DeepFace) of all depictions labelled as \textbf{female}. Furthermore, \textbf{white} remains the dominant race encompassing 59.74\% (FairFace) and 64.16\% (DeepFace) of all depictions. Similarly the dominant ages remain consistent with 81.82\% (FairFace) and 93.77\% (DeepFace) falling within the \textbf{20-29} and \textbf{30-39} age ranges similar to the doctor subset. Furthermore, both models hint at an unbalanced representation with the positive correlations being \textbf{white, female, 20-29, 30-39} however this is even more so in relation to race and age through the evenness values presented in Tables \ref{tab:nurse-shannon-simpson-fairFace} and \ref{tab:nurse-shannon-simpson-deepFace}. Observing the prominence metrics it appears that no significant disparity presents itself in terms of the two genders however it does appear that \textbf{indian} and \textbf{latino hispanic} individuals are less central than their counterparts whilst \textbf{indian} individuals take up less area in an image than \textbf{black} individuals which appear to occupy comparatively more space in relation to their counterparts.  

% The DeepFace annotations depicted that both subsets predominantly consist of \textbf{white} individuals aged \textbf{30-39} with the doctor subset consisting mostly of \textbf{males} whereas the nurse subset of \textbf{females}. On the contrary the FairFace annotations indicated that both subsets mostly comprised of \textbf{white} \textbf{females} aged \textbf{20-29}. In both subsets the gender count was overwhelmingly \textbf{female} as opposed to the DeepFace results which were quite balanced as depicted in Figure \ref{fig:LAION-Gender-Graphs}.

% The correlation results for both subsets hint at the presence of \textbf{race} and \textbf{age} bias as the FairFace doctor annotations contain a positive correlation between \textbf{white, female, 20-29, 30-39}, the same holds true for the nurse subset. On the other hand the DeepFace doctor annotations contain a positive correlation between \textbf{male, asian, white, 20-29, 30-39} whilst the nurse subset contains a positive correlation between \textbf{female, asian, white, 20-29, 30-39}. Finally, this bias is also supported by the lack of evenly distributed race and age labels as outlined in Table \ref{tab:doctor-nurse-evenness-measures}

Taking into consideration the global demographics outlined in Section \ref{Eval-RealWorldBias} in conjunction with the bias identified in Section \ref{Eval-AnnotationBias} one can conclude that considering both groups the majority of doctors and nurses are white, aged 20-39 with nurses being predominantly female. This demographic seems the fit the global consensus regarding nurses this being white females aged 35-44 however this data doesn't align with the doctor global consensus with the majority being males younger than 55 with no clear dominant race. This leads to the conclusion that the LAION-400M doctor subset presents female gender bias and white racial bias in the respective cases when compared against real life data. 

% In light of the fact that the LAION-400M dataset consist of images retrieved from the common crawl a subsequent subset of 285 images was retrieved and processed however the results were similar to those presented prior leading to the same conclusion.

{% In accordance with the FairFace annotations both doctor and nurse subsets mostly consisted of white females aged around 20-29 with the primary distinction being that the nurse subset contained an overwhelming number of females. Furthermore the DeepFace annotations depict a different picture with the majority of doctors being white males aged 30-39 wheres nurses are primarily white females aged 30-39. However the gender split for the nurse subset appears more balanced than that of the FairFace annotations. 

% Taking into account the bias identified in Section \ref{eval-human-ai-comparison} it can be assumed that overall, both subsets consisted predominantly of white woman aged between 20-39, this is also further supported by the correlation results as the FairFace doctor subset had strong positive correlations with the labels \textit{white}, \textit{20-29} whereas it had less decisive positive correlations with \textit{female} and \textit{30-39}, these correlations also present themselves in the DeepFace annotations wherein \textit{white} and \textit{30-39} are strongly correlated and \textit{male}, \textit{asian} and \textit{20-29} less so. The nurse subset on the contrary consists of storng correlation with the labels \textit{white}, \textit{female}, \textit{20-29} and \textit{30-39} further supporting the prior claim. Finally, the overwhelming abundance of singular labels in particular those associated with race and age is also supported by the evenness values denoted in Table \ref{tab:doctor-nurse-evenness-measures}.

% Given these results it is safe to conclude that the majority of images present in these subsets mostly consisted of \textbf{white} individuals aged \textbf{20-39}. Given the less concise gender results no outright assumptions can be made save for the abundance of female nurse depictions. 

% These observation when considered against the real life demographics of individuals in the medical field outline how the doctor dataset depicts a larger degree of female representation in comparison to real world demographics with 59.7\% and 41.03\% of doctor image for the FairFace and DeepFace annotaions being assigned the female label as opposed to the 2018 study by the Association of American Medical Colleges which saw only 35.8\% of doctors as being female \cite{https://www.aamc.org/data-reports/workforce/data/figure-19-percentage-physicians-sex-2018} furthermore a similar study \cite{https://www.aamc.org/data-reports/workforce/data/figure-20-percentage-physicians-sex-and-race/ethnicity-2018} found that the racial distribution amongst both genders was fairly balanced with no race overshadowing the rest. Furthermore \cite{https://www.oecd-ilibrary.org/sites/aa9168f1-en/index.html?itemId=/content/component/aa9168f1-en} showcases how the gender distribution for doctors globally is fairly balanced as of 2019 whilst denoting how the share of doctors aged 55 or older is on the lower end, with only Italy reaching a percentage of 56\% whilst the remaining countries considered having far reduced percentages. In relation to nurses, \cite{https://www.statista.com/statistics/1099804/distribution-of-nurses-across-regions-worldwide-by-gender/} denotes how the majority of nurses are predominantly female as of 2019, this is further supported by a more recent study \cite{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10161512/} denoting how 76.91\% of nurses are female globally. Furthermore, \cite{https://www.aacnnursing.org/news-data/fact-sheets/nursing-workforce-fact-sheet} denotes how the majority of the nursing population is predominantly white (80\%) females (88.8\%). This comparison with real world data denotes that no additional bias is present in the dataset save for that already present in the real world however it indicates that no care was taken into compiling an unbiased training dataset.

% Two subsets of 385 randomly chosen LAION-400M images, labeled as "doctor" and "nurse," were annotated using DeepFace and FairFace models, aligning with chapters 4 and 5. FairFace annotations indicated both subsets mostly comprised white females aged 20-29, with nurses having more females. Conversely, DeepFace annotations depicted most doctors as white males aged 30-39 and nurses as white females aged 30-39, with a more balanced gender split for nurses. Considering biases identified (Section 4.5), both subsets were predominantly white women aged 20-39, supported by correlation results. Table 1 shows singular labels, particularly race and age, were abundant. The doctor subset showed higher female representation compared to real-world demographics, with 59.7\% and 41.03\% female labels in FairFace and DeepFace annotations, respectively, contrasting with the Association of American Medical Colleges' 2018 study citing 35.8\% female doctors [@aamc_physicians_sex_2018]. Global gender distribution among doctors was fairly balanced in 2019, with nurses predominantly female, according to various sources [@oecd_doctors_gender_2019; @statista_nurses_gender_2019; @doi_nursing_population]. Real-world data comparison suggests no additional dataset bias beyond real-world biases, indicating a lack of effort to compile an unbiased training dataset.\\
}
% -------------------------------------------
\section{Stable Diffusion OLD}\label{Eval-StableDiffusion}
The Stable Diffusion generated images consisted of three sets associated with \textit{Doctor}, \textit{Nurse} and \textit{Doctor and Nurse}. 
The doctor subset as annotated by both models saw 88.31\% (FairFace) and 89.61\% (DeepFace) of all images assigned the \textbf{male} label, 71.17\% (FairFace) and 78.18\% (DeepFace) assigned the \textbf{white} race label and 87.79\% (FairFace) and 96.36\% (DeepFace) of all depictions grouped under the \textbf{20-29} and \textbf{30-39} age groups. These same labels also have a positive correlation with the image subject. Furthermore, the evenness values in Tables \ref{tab:doctor-shannon-simpson-fairFace} and \ref{tab:doctor-shannon-simpson-deepFace} further emphasise their prominence in the image set by highlighting the uneven distribution of the labels. Observing the prominence metrics it is clear that no major gender discrepancy presents itself however \textbf{asian} individuals are more prominent as they are depicted closer to the image center and occupy more area than their counterparts as can be seen in Tables \ref{tab:doctor-race-fairFace} and \ref{tab:doctor-race-deepFace}. 

% Looking at the which attributes promote a positive correlation we get \textbf{white, male, 20-29, 30-39} across both annotation schemes and through observation of the evenness values as denoted in Tables \ref{tab:doctor-shannon-simpson-fairFace} and \ref{tab:doctor-shannon-simpson-deepFace} it is clear that these labels dominate the doctor depictions. In relation to the percentage area and distance from center for the doctor images in relation to the two genders no major discrepancies present themselves with the median Percentage Area being around 76\% and 75.39\% wheres the media center distance being around 0.09 and 0.1 for males and females respectively across both annotation models. Contrarily the same cannot be said in relation to race as \textit{asian} individuals were predominantly depicted closer to the center with a normalised distance of 0.045 across both annotation schemes wheres the remaining races saw distances ranging from 0.07 to 0.25. Furthermore, Asian individuals seem to occupy a greater degree of the image with values around 90.72\% where the rest of the races fluctuate between 64.14\% and 84.99\%.

The nurse subset saw 96.62\% (FairFace) and 90.65\% (DeepFace) of all images labelled as \textbf{female} with the dominant race being \textbf{white} at 57.4\% (FairFace) and 68.05\% (DeepFace). However their was a slight discrepancy between the two annotation models in that DeepFace assigned 66.49\% into the \textbf{30-39} age group and 32.21\% into the \textbf{20-29} age group whereas FairFace labelled 95.84\% as fitting into the \textbf{20-29} age group. Similar to prior observations the positive correlation along with the evenness values in Tables \ref{tab:nurse-shannon-simpson-fairFace} and \ref{tab:nurse-shannon-simpson-deepFace} further denote the prominence of these aforementioned labels, however it is crucial to note that the FairFace results do hint at some degree of racial diversity. This is due to \textbf{black} and \textbf{latino hispanic} having positive correlations whilst being decently represented within both sets of results, respectively covering 18.44\% and 22.34\% of all images under FairFace and 15.84\% and 12.47\% under DeepFace. Observing the prominence results both genders appear to be equally prominent. In relation to race considering those with adequate representation it appears that \textbf{black} individuals seem to be slightly more prominent than their counterparts.   

% The nurse subset as annotated via FairFace saw 96.62\% of all images labelled as female with the dominant race being white at 57.4\% and the dominant age group being 20-29 at 95.84\%. The DeepFace annotations depict a similar image with 90.65\% of images assigned the female label, 68.05\% the white label and 66\% the 30-39 age group however 32.21\% still fall under the 20-29 age group. Furthermore, the positively correlated labels are \textbf{white, female, 20-29}, however the FairFace annotations also denote \textbf{latino hispanic, black} as positively correlated which coincides with the results seeing as these are the other races for which their is adequate representation with 22.33\% and 18.44\% respectively. Through observing the evenness values in Tables \ref{tab:nurse-shannon-simpson-fairFace} and \ref{tab:nurse-shannon-simpson-deepFace} it is clear that a dominant label exists save for the race which although not perfectly balanced does see greater representation in terms of black and latino hispanic individuals. Considering the median area and center distance in relation to gender no major discrepancy is depicted similarly this also holds when observed from a racial perspective as excluding the asian, middle easter and indian race instances, seeing as they had minimal representation, the remaining races had median center distance ranging from 0.05 to 0.1 across both annotation mediums and area values ranging from 69.5\% to 90.64\%.

The final subset considered is the doctor and nurse subset. The annotations provided via both annotation models depict a fair gender split with a 42.21\% male and 57.79\% female split via the FairFace annotaitons and a 51.94\% male and 48.05\% female split via DeepFace.  Contrarily both models outlines how 71.69\% (FairFace) and 76.49\% (DeepFace) are \textbf{white} with 88.18\% (FairFace) and 94.16\% (DeepFace) falling under the \textbf{20-29} and \textbf{30-39} age groups. Observing the positive correlations both models support the claims presented, whilst being further supported by the evenness values depicted in Tables \ref{tab:doctor-nurse-shannon-simpson-fairFace} and \ref{tab:doctor-nurse-shannon-simpson-deepFace} which denote an even split between gender labels whilst reduced evenness in the race and age labels. Taking into consideration the prominence metrics showcases no major disparity across both annotation methods in terms of both gender and race, with the latter excluding underrepresented races.

% -----------------------------------------------------

To conclude on the potential biases in  the Stable Diffusion model comparison is carried out with both real-world data presented in Section \ref{Eval-RealWorldBias} and the LAION-400M dataset. Notably, the model generates a disproportionate number of male doctors around 88.96\%, compared to the real-world doctor population, which is roughly 64\% male. Racial bias is also apparent, with a significant majority of generated doctors being white approximately 74.68\%. Similarly, age distribution seems skewed towards younger doctors, with 92.08\% appearing under 55 years old, while the real world reflects a lower proportion (66\%) younger than said age. Through comparison with the LAION-400M demographics as presented in Section \ref{Eval-Laion400MBias} its clear that the model perpetuates gender bias as the LAION-400M dataset appears to be fairly balanced in its gender depictions whereas the model is not and even goes beyond real world biases. Contrarily, it seems that the model is not race or age biased as although the measurements are slightly higher than those outlined for the LAION-400M dataset the main bias appears to originate from the training dataset itself and not the model. In relation to person prominence it appears that no bias presents itself in relation to gender however \textbf{asian} individuals appear to be depicted more prominently within said model.

Observing the nurse subset their appears to be an increase in \textbf{female} depictions around 93.64\% as opposed to the 88.8\% global metric, additionally nurse depictions are biased towards younger individuals having around 97.27\% of all depictions fall within the 20-39 age range as opposed to the real world, wherein 29.1\% of all nurses fall within the 35-44 age range. However \textbf{white} representation is reduced to around 62.73\% as opposed to the 80\% observed globally. Further comparison with the LAION-400M dataset outlines the presence of innate model bias as the \textbf{female} depictions far exceeded those of the dataset (66.24\%). Similarly it appears that the model is biased towards the \textbf{20-39} age range having a higher percentage representation than that of the dataset (87.8\%). Contrarily it appears that the reduction in \textbf{white} representation seen within the model when compared to the real world demographics is due to training dataset. Thus, it can be concluded that the model is biased towards \textbf{female} and \textbf{20-39} representation however presenting no innate racial bias save for that already present within the dataset. In relation to person prominence it appears that no bias presents itself in relation to gender however \textbf{black} individuals appear to be depicted more prominently within said model.

In relation to the doctor and nurse subset it appears that whilst the gender bias appears to be diminished having fairly equal representation of both genders it appears that the racial and age bias outlined for the doctor only and nurse only images is still pertinent. This leads to the conclusion that the gender bias has not truly diminished rather most doctors have been depicted as male and most nurses as female and as such the metric has evened out. The same appears to have occurred in relation to the prominence metrics as no clear gender or racial bias presents itself. 

% In line with the results outlined prior it is clear that the Stable Diffusion model perpetuates gender, race and age bias. However these results must  

% suffers from gender bias predominantly when considering strictly doctors or nurses. This is due to the fact that the dominant gender for doctor depictions was overwhelmingly \textbf{male}, ranging from 88\% to 89\% across both annotation models. This also far exceeds the 64.2\% male doctor population outlined in Section \ref{Eval-RealWorldBias}. The same holds true for the nurse depictions with 90.65\% to 96.62\% being female as opposed to the real world value of 76.91\%. Furthermore, it is this innate gender bias which most likely results in the balanced gender depictions when concerned with the \textit{doctor and nurse} subset. 

% However, the Stable Diffusion model seemingly reduces racial bias within the nurse subset as only 57\%-68\% of all depictions are white as opposed to the 80\% in the real world. This does not seem to be the case with the doctor subset however as the majority of doctors are white as opposed to the balanced representation seen in the real world. Finally, in terms of age no bias seems to present itself as the majority of doctors and nurses fall between the 20-39 age range which coincides with the real world metrics. Further comparing the metrics to those of the LAION-400M dataset discussed earlier it is clear that the Stable Diffusion model is overly male biased in relation to depictions of doctors as opposed to female biased as one would initially assume given the training data, furthermore it also seems to reinforce and strengthen the bias already present in the LAION-400M dataset.