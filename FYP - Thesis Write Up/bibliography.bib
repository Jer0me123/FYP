@online{midjourney,
author = {{Midjourney}},
year = {2022},
month = {July},
title = {Midjourney},
howpublished = {https://www.midjourney.com/home},
note = {(Accessed Oct. 29, 2023)},
abstract = {Midjourney is an independent research lab exploring new mediums of thought and expanding the imaginative powers of the human species. We are a small self-funded team focused on design, human infrastructure, and AI. We have 11 full-time staff and an incredible set of advisors.},
}

@online{dall-e-2,
author = {{DALL·E 2}},
year = {2022},
month = {April},
title = {DALL·E 2},
howpublished = {https://openai.com/dall-e-2},
note = {(Accessed Oct. 29, 2023)},
abstract ={OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity.},
}

@online{stable-diffusion-online,
author = {{Stable Diffusion}},
year = {2022},
month = {August},
title = {Stable Diffusion Online},
howpublished = {\url{https://stablediffusionweb.com/}},
note = {Accessed on Oct. 29, 2023},
abstract = {Stable Diffusion XL is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, cultivates autonomous freedom to produce incredible imagery, empowers billions of people to create stunning art within seconds.}
}

@article{Controllable-Generative-Adversarial-Network,
  author={Lee, Minhyeok and Seok, Junhee},
  journal={IEEE Access}, 
  title={Controllable Generative Adversarial Network}, 
  year={2019},
  volume={7},
  pages={28158-28169},
  doi={10.1109/ACCESS.2019.2899108}}

@article{GAN-Privacy-Ethics-Concerns,
author={Sudhir Bale, Ajay and Dhumale, R. B. and Beri, Nimisha and Lourens, Melanie and Varma, Raj A. and Kumar, Vinod and Sanamdikar, Sanjay and Savadatti, Mamta B.},
title={The Impact of Generative Content on Individuals Privacy and Ethical Concerns},
volume={12}, 
url={https://www.ijisae.org/index.php/IJISAE/article/view/3503}, 
abstractNote={&amp;lt;p&amp;gt;The rise of AI and ML-fueled generative content technologies has altered every stage of the content life cycle, from creation to distribution to consumption. There are many positive outcomes from these breakthroughs, but there are also serious ethical and privacy problems. The purpose of this work is to investigate the wide-ranging effects of generative content on personal data security and ethical considerations. The article dives into the privacy concerns that may arise from using generative material. Since this kind of technology depends heavily on user data, the ease with which accurate and tailored content may be generated raises concerns about data privacy. Unauthorized content synthesis, which may lead to the proliferation of bogus data, counterfeits, and other types of illicit tampering, is also a source of worry. We have attempted to consider all these implications and delve into them to bring out possible solutions. We are optimistic that this article will provide future insights into the research of generative content and its ethical considerations.&amp;lt;/p&amp;gt;}, number={1s}, 
journal={International Journal of Intelligent Systems and Applications in Engineering}, 
author={Sudhir Bale, Ajay and Dhumale, R. B. and Beri, Nimisha and Lourens, Melanie and Varma, Raj A. and Kumar, Vinod and Sanamdikar, Sanjay and Savadatti, Mamta B.}, 
year={2023}, 
month={Sep.}, 
pages={697–703} }

@article{Bias-Gender-Race,
author = {Ntoutsi, Eirini and Fafalios, Pavlos and Gadiraju, Ujwal and Iosifidis, Vasileios and Nejdl, Wolfgang and Vidal, Maria-Esther and Ruggieri, Salvatore and Turini, Franco and Papadopoulos, Symeon and Krasanakis, Emmanouil and Kompatsiaris, Ioannis and Kinder-Kurlanda, Katharina and Wagner, Claudia and Karimi, Fariba and Fernandez, Miriam and Alani, Harith and Berendt, Bettina and Kruegel, Tina and Heinze, Christian and Broelemann, Klaus and Kasneci, Gjergji and Tiropanis, Thanassis and Staab, Steffen},
title = {Bias in data-driven artificial intelligence systems—An introductory survey},
journal = {WIREs Data Mining and Knowledge Discovery},
volume = {10},
number = {3},
pages = {e1356},
keywords = {fairness, fairness-aware AI, fairness-aware machine learning, interpretability, responsible AI},
doi = {https://doi.org/10.1002/widm.1356},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1356},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1356},
abstract = {Abstract Artificial Intelligence (AI)-based systems are widely employed nowadays to make decisions that have far-reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well-grounded in a legal frame. In this survey, we focus on data-driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth. This article is categorized under: Commercial, Legal, and Ethical Issues > Fairness in Data Mining Commercial, Legal, and Ethical Issues > Ethical Considerations Commercial, Legal, and Ethical Issues > Legal Issues},
year = {2020}
}

@online{COMPASS-situation-racial-bias,
  author = {Julia Angwin and Jeff Larson and Lauren Kirchner and Surya Mattu},
  title = {Machine Bias},
  year = {2016},
  organization = {ProPublica},
  url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  note = {Accessed on 29 October 2023},
}

@article{Discrimination-in-Online-Ad-Delivery,
author = {Sweeney, Latanya},
title = {Discrimination in Online Ad Delivery},
year = {2013},
issue_date = {May 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {5},
issn = {0001-0782},
url = {https://doi.org/10.1145/2447976.2447990},
doi = {10.1145/2447976.2447990},
abstract = {Google ads, black names and white names, racial discrimination, and click advertising.},
journal = {Commun. ACM},
month = {may},
pages = {44–54},
numpages = {11}
}

@article{Facial-Recognition-Negative-Consequnces,
  author={Cook, Cynthia M. and Howard, John J. and Sirotin, Yevgeniy B. and Tipton, Jerry L. and Vemury, Arun R.},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science}, 
  title={Demographic Effects in Facial Recognition and Their Dependence on Image Acquisition: An Evaluation of Eleven Commercial Systems}, 
  year={2019},
  volume={1},
  number={1},
  pages={32-41},
  doi={10.1109/TBIOM.2019.2897801}}

@techreport{Credit-Scoring-Negative-Consequnces,
 title = "Consumer-Lending Discrimination in the FinTech Era",
 author = "Bartlett, Robert and Morse, Adair and Stanton, Richard and Wallace, Nancy",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "25943",
 year = "2019",
 month = "June",
 doi = {10.3386/w25943},
 URL = "http://www.nber.org/papers/w25943",
 abstract = {Discrimination in lending can occur either in face-to-face decisions or in algorithmic scoring. We provide a workable interpretation of the courts’ legitimate-business-necessity defense of statistical discrimination. We then estimate the extent of racial/ethnic discrimination in the largest consumer-lending market using an identification afforded by the pricing of mortgage credit risk by Fannie Mae and Freddie Mac. We find that lenders charge Latinx/African-American borrowers 7.9 and 3.6 basis points more for purchase and refinance mortgages respectively, costing them $765M in aggregate per year in extra interest. FinTech algorithms also discriminate, but 40% less than face-to-face lenders. These results are consistent with both FinTech and non-FinTech lenders extracting monopoly rents in weaker competitive environments or profiling borrowers on low-shopping behavior. Such strategic pricing is not illegal per se, but under the law, it cannot result in discrimination. The lower levels of price discrimination by algorithms suggests that removing face-to-face interactions can reduce discrimination. Further silver linings emerge in the FinTech era: (1) Discrimination is declining; algorithmic lending may have increased competition or encouraged more shopping with the ease of platform applications. (2) We find that 0.74-1.3 million minority applications were rejected between 2009 and 2015 due to discrimination; however, FinTechs do not discriminate in loan approval.},
}

@inproceedings{revisetool_eccv,
author = {Angelina Wang and Arvind Narayanan and Olga Russakovsky},
title = {{REVISE}: A Tool for Measuring and Mitigating Bias in Visual Datasets},
year = {2020},
booktitle = {European Conference on Computer Vision (ECCV)},
}

@article{RefWorks:RefID:30-fabbrizzi2022survey,
	author={Simone Fabbrizzi and Symeon Papadopoulos and Eirini Ntoutsi and Ioannis Kompatsiaris},
	year={2022},
	title={A survey on bias in visual datasets},
	journal={Computer Vision and Image Understanding},
	volume={223},
	pages={103552},
	note={ID: 271018},
	abstract={Computer Vision (CV) has achieved remarkable results, outperforming humans in several tasks. Nonetheless, it may result in significant discrimination if not handled properly. Indeed, CV systems highly depend on training datasets and can learn and amplify biases that such datasets may carry. Thus, the problem of understanding and discovering bias in visual datasets is of utmost importance; yet, it has not been studied in a systematic way to date. Hence, this work aims to: (i) describe the different kinds of bias that may manifest in visual datasets; (ii) review the literature on methods for bias discovery and quantification in visual datasets; (iii) discuss existing attempts to collect visual datasets in a bias-aware manner. A key conclusion of our study is that the problem of bias discovery and quantification in visual datasets is still open, and there is room for improvement in terms of both methods and the range of biases that can be addressed. Moreover, there is no such thing as a bias-free dataset, so scientists and practitioners must become aware of the biases in their datasets and make them explicit. To this end, we propose a checklist to spot different types of bias during visual dataset collection.},
	keywords={Computer vision; Visual datasets; Bias; AI ethics},
	isbn={1077-3142},
	url={https://www-sciencedirect-com.ejournals.um.edu.mt/science/article/pii/S1077314222001308},
	doi={10.1016/j.cviu.2022.103552}
}

@misc{clip-retrieval,
  author = {Romain Beaumont},
  title = {Clip Retrieval: Easily compute clip embeddings and build a clip retrieval system with them},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/rom1504/clip-retrieval}}
}

@article{coop,
   title={Learning to Prompt for Vision-Language Models},
   volume={130},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-022-01653-1},
   DOI={10.1007/s11263-022-01653-1},
   number={9},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
   year={2022},
   month=jul, pages={2337–2348} }

@article{face-recognition,
  title={Face recognition algorithms},
  author={De Carrera, Proyecto Fin and Marques, Ion},
  journal={Master's thesis in Computer Science, Universidad Euskal Herriko},
  volume={1},
  year={2010}
}

@article{face-recognition-2,
  title={Video-based face recognition: A survey},
  author={Wang, Huafeng and Wang, Yunhong and Cao, Yuan},
  journal={International Journal of Computer and Information Engineering},
  volume={3},
  number={12},
  pages={2809--2818},
  year={2009}
}

@inproceedings{face-recognition-3,
issn = {0302-9743},
abstract = {We describe progress in the automatic detection and identification of humans in video, given a minimal number of labelled faces as training data. This is an extremely challenging problem due to the many sources of variation in a person’s imaged appearance: pose variation, scale, illumination, expression, partial occlusion, motion blur, etc.
The method we have developed combines approaches from computer vision, for detection and pose estimation, with those from machine learning for classification. We show that the identity of a target face can be determined by first proposing faces with similar pose, and then classifying the target face as one of the proposed faces or not. Faces at poses differing from those of the training data are rendered using a coarse 3-D model with multiple texture maps. Furthermore, the texture maps of the model can be automatically updated as new poses and expressions are detected. We demonstrate results of detecting three characters in a TV situation comedy.},
pages = {289--298},
volume = {3115},
publisher = {Springer Berlin Heidelberg},
booktitle = {IMAGE AND VIDEO RETRIEVAL, PROCEEDINGS},
isbn = {9783540225393},
year = {2004},
title = {Automated Person Identification in Video},
copyright = {Springer-Verlag Berlin Heidelberg 2004},
language = {eng},
address = {Berlin, Heidelberg},
author = {Everingham, Mark and Zisserman, Andrew},
keywords = {Applied sciences ; Artificial intelligence ; Computer Science ; Computer Science Artificial Intelligence ; Computer Science Information Systems ; Computer Science Theory & Methods ; Computer science; control theory; systems ; Exact sciences and technology ; Face Detection ; Facial Expression ; Imaging Science & Photographic Technology ; Information systems. Data bases ; Memory organisation. Data processing ; Motion Blur ; Pattern recognition. Digital image processing. Computational geometry ; Science & Technology ; Software ; Target Face ; Target Frame ; Technology},
}

@article{face-recognition-pipeline,
  title={Face recognition: A literature survey},
  author={Zhao, W. and Chellappa, R. and Rosenfeld, A. and Phillips, P.},
  journal={ACM Computing Surveys},
  pages={399--458},
  year={2003}
}

@book{face-recognition-book,
  title={Face recognition algorithms},
  author={Marques, Ion},
  year={2010}
}


@inproceedings{deepFace-ref-1,
  title        = {LightFace: A Hybrid Deep Face Recognition Framework},
  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},
  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},
  pages        = {23-27},
  year         = {2020},
  doi          = {10.1109/ASYU50717.2020.9259802},
  url          = {https://doi.org/10.1109/ASYU50717.2020.9259802},
  organization = {IEEE}
}

@inproceedings{deepFace-ref-2,
  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},
  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},
  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},
  pages        = {1-4},
  year         = {2021},
  doi          = {10.1109/ICEET53442.2021.9659697},
  url          = {https://doi.org/10.1109/ICEET53442.2021.9659697},
  organization = {IEEE}
}

@misc{inferdo,
  title = {Computer Vision API},
  howpublished = {\url{https://inferdo.com/}},
  note = {Accessed: 05 November 2023},
}

@misc{betaFace,
  title = {Betaface API},
  howpublished = {\url{https://www.betafaceapi.com/wpa/}},
  note = {Accessed: 05 November 2023},
}

@online{ILOSTAT-job-bias,
  author    = {{International Labour Organization}},
  title     = {These Occupations Are Dominated by Women},
  year      = {2020},
  url       = {https://ilostat.ilo.org/these-occupations-are-dominated-by-women/},
  note      = {Accessed Nov. 19, 2023},
}

@online{CareerSmart-job-bias,
  author    = {{Career Smart}},
  title     = {Which Jobs Do Men and Women Do? Occupational Breakdown by Gender},
  year      = {2018},
  url       = {https://careersmart.org.uk/occupations/equality/which-jobs-do-men-and-women-do-occupational-breakdown-gender},
  note      = {Accessed 19 November 2023},
}

@article{clip-prompting,
   title={Learning to Prompt for Vision-Language Models},
   volume={130},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-022-01653-1},
   DOI={10.1007/s11263-022-01653-1},
   number={9},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
   year={2022},
   month=jul, pages={2337–2348} }

@online{LAION5BClipSearch,
  title = {Clip Front},
  howpublished = {\url{https://rom1504.github.io/clip-retrieval/?back=https%3A%2F%2Fknn.laion.ai&index=laion5B-H-14&useMclip=false&query=doctor}},
  note = {Accessed 19 November 2023}
}

@online{Google-monk-skin-tone-annotations,
  author       = {Schumann, C. and Olanubi, G.O.},
  title        = {Consensus and subjectivity of skin tone annotation for ML fairness},
  year         = {2023},
  organization = {Google Research. Google},
  month        = {May 15},
  note = {Accessed: 19 November 2023},
  howpublished ={\url{https://blog.research.google/2023/05/consensus-and-subjectivity-of-skin-tone_15.html}},
}

@misc{BiasDetectionPipeline-schaaf2021measuring,
      title={Towards Measuring Bias in Image Classification}, 
      author={Nina Schaaf and Omar de Mitri and Hang Beom Kim and Alexander Windberger and Marco F. Huber},
      year={2021},
      eprint={2107.00360},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{fiverr,
  title = {Fiverr},
  howpublished = {\url{https://www.fiverr.com}},
  note = {Accessed on November 29, 2023}
}

@misc{LAION_5B_Known_Bias,
  author = {LAION},
  title = {laion5b-bias},
  version = {1.0.0},
  date = {2022-05-17},
  howpublished = {\url{https://github.com/LAION-AI/laion5b-bias})
}

@misc{LAION_5B_Known_Bias_2,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      year={2022},
      eprint={2210.08402},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{UncoveringBiasintheFaceProcessingPipeline,
author="Galea, Christian
and Saliba, Chantelle
and Sacco, Matthew
and Bugeja, Mark
and Buttigieg, Noel
and Seychell, Dylan",
editor="Basili, Roberto
and Lembo, Domenico
and Limongelli, Carla
and Orlandini, Andrea",
title="Uncovering Bias in the Face Processing Pipeline: An Analysis of Popular and State-of-the-Art Algorithms Across Demographic Groups",
booktitle="AIxIA 2023 -- Advances in Artificial Intelligence",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="245--264",
abstract="Numerous algorithms process face images to perform tasks such as person identification and estimation of attributes such as the race and gender. While previous work has focused on biases in face recognition systems, relatively limited work has considered the full face processing pipeline to determine if other components also exhibit any biases related to a person's demographic attributes. An evaluation of popular and state-of-the-art methods in the face processing pipeline reveals that, although the overall performance may appear satisfactory, numerous differences are uncovered when digging deeper to consider the performance not just within a single demographic group, but also across different types of groups. Several avenues of future work are also provided.",
isbn="978-3-031-47546-7"
}

@ARTICLE{dall-e-3-paper,
  author = {Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and Manassra, Wesam and Dhariwal, Prafulla and Chu, Casey and Jiao, Yunxin and Ramesh, Aditya},
  title = {Improving Image Generation with Better Captions},
  year = {2023},
  url = {https://cdn.openai.com/papers/dall-e-3.pdf}
}

@misc{stable-diffusion-paper,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{stablediffusion-process-explained,
  author = {Amazon Web Services},
  title = {What is Stable Diffusion?},
  url = {https://aws.amazon.com/what-is/stable-diffusion/},
  year = {2024}
}

@misc{midjourney-pickfu-article,
  author = {Melchor, Laura},
  title = {Midjourney vs Stable Diffusion: which tool should you use?},
  url = {[https://www.pickfu.com/blog/midjourney-vs-stable-diffusion/](https://www.pickfu.com/blog/midjourney-vs-stable-diffusion/)},
  year = {2023},
  note = {PickFu Blog}
}

@misc{clip-paper,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
    url = {https://arxiv.org/pdf/2103.00020.pdf}
}

@online{zero-shot-learning,
  author    = {AlphaMoon},
  title     = {Zero-Shot Learning: A Comprehensive Guide},
  year      = {2023},
  url       = {https://alphamoon.ai/blog/zero-shot-learning/},
  note      = {Accessed: February 20, 2024}
}

@online{stable-diffusion-clip-reference,
  author    = {Agrawal, Aayush},
  title     = {Stable Diffusion Using Hugging Face},
  year      = {2022},
  url       = {https://towardsdatascience.com/stable-diffusion-using-hugging-face-501d8dbdd8},
  note      = {Accessed: February 20, 2024}
}

@online{dall-e-clip-reference,
  author      = {Singh, Aditya},
  title       = {How Does DALL-E 2 Work?},
  year        = {2022},
  url         = {https://medium.com/augmented-startups/how-does-dall-e-2-work-e6d492a2667f},
  note        = {Medium},
}

@online{diffusion-models-explained,
    author = {Ahirwar, Kailash},
    title = {A Very Short Introduction to Diffusion Models},
    year = {2023},
    url = {https://kailashahirwar.medium.com/a-very-short-introduction-to-diffusion-models-a84235e4e9ae},
}

@Article{faceImageAnalysis,
AUTHOR = {Siddiqi, Muhammad Hameed and Khan, Khalil and Khan, Rehan Ullah and Alsirhani, Amjad},
TITLE = {Face Image Analysis Using Machine Learning: A Survey on Recent Trends and Applications},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {8},
ARTICLE-NUMBER = {1210},
URL = {https://www.mdpi.com/2079-9292/11/8/1210},
ISSN = {2079-9292},
ABSTRACT = {Human face image analysis using machine learning is an important element in computer vision. The human face image conveys information such as age, gender, identity, emotion, race, and attractiveness to both human and computer systems. Over the last ten years, face analysis methods using machine learning have received immense attention due to their diverse applications in various tasks. Although several methods have been reported in the last ten years, face image analysis still represents a complicated challenge, particularly for images obtained from &rsquo;in the wild&rsquo; conditions. This survey paper presents a comprehensive review focusing on methods in both controlled and uncontrolled conditions. Our work illustrates both merits and demerits of each method previously proposed, starting from seminal works on face image analysis and ending with the latest ideas exploiting deep learning frameworks. We show a comparison of the performance of the previous methods on standard datasets and also present some promising future directions on the topic.},
DOI = {10.3390/electronics11081210}
}

@inproceedings{facialAnalysisSurveillance,
author = {Benfold, Ben and Reid, Ian},
year = {2009},
month = {01},
pages = {},
title = {Guiding Visual Surveillance by Tracking Human Attention},
journal = {British Machine Vision Conference, BMVC 2009 - Proceedings},
doi = {10.5244/C.23.14}
}

@ARTICLE{facialAnalysisAdvertisement,
  author={Smith, Kevin and Ba, Sileye O. and Odobez, Jean-Marc and Gatica-Perez, Daniel},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Tracking the Visual Focus of Attention for a Varying Number of Wandering People}, 
  year={2008},
  volume={30},
  number={7},
  pages={1212-1229},
  keywords={Hidden Markov models;Layout;Advertising;Cameras;Current measurement;Cognitive science;Bayesian methods;Consumer products;Displays;TV;Image Processing and Computer Vision;Tracking;Scene Analysis;Computer vision;Marketing;Image Processing and Computer Vision;Tracking;Scene Analysis;Computer vision;Marketing},
  doi={10.1109/TPAMI.2007.70773}}

@Article{facialAnalysisDriving,
AUTHOR = {Braun, Michael and Schubert, Jonas and Pfleging, Bastian and Alt, Florian},
TITLE = {Improving Driver Emotions with Affective Strategies},
JOURNAL = {Multimodal Technologies and Interaction},
VOLUME = {3},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2414-4088/3/1/21},
ISSN = {2414-4088},
ABSTRACT = {Drivers in negative emotional states, such as anger or sadness, are prone to perform bad at driving, decreasing overall road safety for all road users. Recent advances in affective computing, however, allow for the detection of such states and give us tools to tackle the connected problems within automotive user interfaces. We see potential in building a system which reacts upon possibly dangerous driver states and influences the driver in order to drive more safely. We compare different interaction approaches for an affective automotive interface, namely Ambient Light, Visual Notification, a Voice Assistant, and an Empathic Assistant. Results of a simulator study with 60 participants (30 each with induced sadness/anger) indicate that an emotional voice assistant with the ability to empathize with the user is the most promising approach as it improves negative states best and is rated most positively. Qualitative data also shows that users prefer an empathic assistant but also resent potential paternalism. This leads us to suggest that digital assistants are a valuable platform to improve driver emotions in automotive environments and thereby enable safer driving.},
DOI = {10.3390/mti3010021}
}

@article{bias-types-visual-datasets,
  author    = {Fabbrizzi, Simone and Zhao, Xuan and Krasanakis, Emmanouil and Papadopoulos, Symeon and Ntoutsi, Eirini},
  title     = {Studying Bias in Visual Features through the Lens of Optimal Transport},
  journal   = {Data Mining and Knowledge Discovery},
  year      = {2024},
  volume    = {38},
  number    = {1},
  pages     = {281--312},
  month     = {January 1},
  doi       = {10.1007/s10618-023-00972-2},
  issn      = {1573-756X},
  url       = {https://doi.org/10.1007/s10618-023-00972-2},
}

@article{gender-bias-nurse,
  title={Current Stereotypes Associated with Nursing and Nursing Professionals: An Integrative Review},
  author={Teresa-Morales, C and Rodríguez-Pérez, M and Araujo-Hernández, M and Feria-Ramírez, C},
  journal={International Journal of Environmental Research and Public Health},
  volume={19},
  number={13},
  pages={7640},
  year={2022},
  month={Jun},
  doi={10.3390/ijerph19137640},
  PMID={35805296},
  PMCID={PMC9265497}
}

@article{gender-bias-doctor-nurse,
  title={The Relationship Between Physician/Nurse Gender and Patients' Correct Identification of Health Care Professional Roles in the Emergency Department},
  author={Laurie A., Boge and Carlos Dos, Santos and Lisa A., Moreno-Walton and Luigi X., Cubeddu and David A., Farcy},
  journal={Journal of Women's Health},
  year={2019},
  volume={28},
  number={7},
  doi={10.1089/jwh.2018.7571}
}

@article{online-images-amplify-gender-bias,
  title={Online images amplify gender bias},
  author={Guilbeault, Douglas and Delecourt, Solène and Hull, Tasker and Desikan, Bhargav Srinivasa and Chu, Mark and Nadler, Ethan},
  journal={Nature},
  year={2024},
  volume={Volume Number},
  number={Issue Number},
  pages={Page Range},
  abstract={Each year, people spend less time reading and more time viewing images, which are proliferating online. Images from platforms such as Google and Wikipedia are downloaded by millions every day, and millions more are interacting through social media, such as Instagram and TikTok, that primarily consist of exchanging visual content. In parallel, news agencies and digital advertisers are increasingly capturing attention online through the use of images, which people process more quickly, implicitly and memorably than text. Here we show that the rise of images online significantly exacerbates gender bias, both in its statistical prevalence and its psychological impact. We examine the gender associations of 3,495 social categories (such as 'nurse' or 'banker') in more than one million images from Google, Wikipedia, and Internet Movie Database (IMDb), and in billions of words from these platforms. We find that gender bias is consistently more prevalent in images than text for both female- and male-typed categories. We also show that the documented underrepresentation of women online is substantially worse in images than in text, public opinion, and US census data. Finally, we conducted a nationally representative, preregistered experiment that shows that googling for images rather than textual descriptions of occupations amplifies gender bias in participants' beliefs. Addressing the societal effect of this large-scale shift towards visual communication will be essential for developing a fair and inclusive future for the internet.},
  issn={1476-4687},
  url={https://doi.org/10.1038/s41586-024-07068-x},
  doi={10.1038/s41586-024-07068-x}
}

@misc{LAION5B-mainpage,
  author = {LAION Team},
  title = {LAION-5B: A NEW ERA OF OPEN LARGE-SCALE MULTI-MODAL DATASETS | LAION},
  year = {2022},
  url = {https://laion.ai/blog/laion-5b/},
}

@misc{commoncrawl_faq,
  author = {Common Crawl},
  title = {Frequently Asked Questions},
  url = {https://commoncrawl.org/faq},
  accessed = {2024-02-23},
}

@online{dalle3-prompt-guide,
  author = "OpenAI",
  title = "Image generation",
  url = "https://platform.openai.com/docs/guides/images/introduction?context=node",
  note = "Accessed: February 23, 2024",
}

@online{dalle3-tips-thread,
  title = {DALLE3 Prompt Tips and Tricks Thread},
  author = {PaulBellow},
  year = {2023},
  url = {https://community.openai.com/t/dalle3-prompt-tips-and-tricks-thread/498040},
  note = {Published on OpenAI Forum},
}


@online{midjourney-prompt-guide,
  author = {{Midjourney Team}},
  title = {Prompts - Midjourney Documentation},
  url = {https://docs.midjourney.com/docs/prompts-2},
  note = {[Online]}
}

@software{stablediffusion-webui-repo-wiki,
  author = {AUTOMATIC1111},
  title = {Stable Diffusion WebUI},
  year = {2023},
  url = {https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features},
  publisher = {GitHub},
}

@misc{stable-diffusion-prompt-guide,
  author = {Stable Diffusion Art Team},
  title = {Stable Diffusion prompt: a definitive guide},
  year = {2023},
  url = {https://stable-diffusion-art.com/prompt-guide/},
  accessed = {2024-02-23},
}

@INPROCEEDINGS{gender-classification-SVM,
  author={Moghaddam, B. and Ming-Hsuan Yang},
  booktitle={Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)}, 
  title={Gender classification with support vector machines}, 
  year={2000},
  volume={},
  number={},
  pages={306-311},
  keywords={Support vector machines;Support vector machine classification;Testing;Humans;Pixel;Image databases;Visual databases;Error analysis;Image resolution;Robustness},
  doi={10.1109/AFGR.2000.840651}}

@INPROCEEDINGS{gender-classification-RBF,
  author={Lee, Chien-Cheng},
  booktitle={2014 International Conference on Signal Processing and Multimedia Applications (SIGMAP)}, 
  title={Gender classification using M-estimator based radial basis function neural network}, 
  year={2014},
  volume={},
  number={},
  pages={302-306},
  keywords={Feature extraction;Hair;Face;Radial basis function networks;Nose;Time series analysis;Radial Basis Function Neural Network;M-Estimator;Gender Classification},
  doi={}}

@online{facebook-facial-recognition-shut-down,
  author = {The Hacker News},
  title = {Facebook to shut down facial recognition system and delete billions of Records},
  year = {2021},
  url = {https://thehackernews.com/2021/11/facebook-to-shut-down-facial.html},
  note = {Accessed on 24 February 2024}
}


