{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Snippet 1\n",
    "\n",
    "Description: Code used to extract the data of the LAION-400M parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def LoadLAION_400MImages(parquet_file_paths, labels):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This function is used to retrieve the image from the LAION-400M parquet files retrieved from Kaggle.\n",
    "    \n",
    "    Parameters:\n",
    "    parquet_file_paths (list) - List containing the parquet file paths.\n",
    "    labels (list) - List containing the labels to query the images.\n",
    "\n",
    "    Returns:\n",
    "    img_url_dict (dict) - Dict containing the text and urls of the relevant images.\n",
    "    \"\"\"\n",
    "    img_url_dict = {new_list: [] for new_list in labels}\n",
    "    \n",
    "    for parquet_file_path in parquet_file_paths:\n",
    "        # Reading the contents of the parquet file\n",
    "        df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "        # Looping through the dataframe\n",
    "        for index in range(len(df)):\n",
    "            # Removing any NSFW images\n",
    "            if df[\"NSFW\"][index] != \"NSFW\":\n",
    "                # Looping through the labels\n",
    "                for label in labels:\n",
    "                        # Checking if the label is in the text\n",
    "                        if df['TEXT'][index] != None and label.lower() in df['TEXT'][index].lower().split():   \n",
    "                            img_url_dict[label].append({\"text\": df[\"TEXT\"][index], \"url\":df['URL'][index]})\n",
    "            \n",
    "    return img_url_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Snippet 2\n",
    "\n",
    "Description: Code used to access links and retrieve their associated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def RetrieveImagesFromLinks(listOfImageLinks):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This function is used to retrieve images from the links.\n",
    "    \n",
    "    Parameters:\n",
    "    listOfImageLinks (list) - List containing the image links to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    images (list) - List containing the retrieved images.\n",
    "    failedToGetImageCounter (int) - Counter keeping track of how many images were not retrieved.\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    \n",
    "    # Progress bar used to keep track of process execution\n",
    "    progress_bar = tqdm(total=len(listOfImageLinks), desc=\"Processing\", unit=\"links\")\n",
    "    \n",
    "    # Counter used to keep track of how many images were not retrieved\n",
    "    failedToGetImageCounter = 0\n",
    "    \n",
    "    for img_url in listOfImageLinks:\n",
    "        try:\n",
    "            # timeout added in case image takes too long to retrive from link \n",
    "            image_data = urllib.request.urlopen(img_url['url'], timeout=10)\n",
    "            \n",
    "            # Converting the image to .jpg\n",
    "            img = plt.imread(image_data, format='jpg')\n",
    "            \n",
    "            # Checking that the image is of the correct type\n",
    "            if img.dtype != np.uint8:\n",
    "                # Fixing images of type float32\n",
    "                if img.dtype == np.float32:\n",
    "                    img = (img * 255).astype(np.uint8)\n",
    "            \n",
    "            # Adding the image to images list\n",
    "            images.append(img)\n",
    "        except Exception as error:\n",
    "            failedToGetImageCounter+=1\n",
    "        \n",
    "        # Updating the progress bar\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    return images, failedToGetImageCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Snippet 3\n",
    "Description: Code used to filter out images which contain no people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def RemoveImageNotContainingPeople(images, confidence_threshold=0.5):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This function serves to remove images which don't contain people within them.\n",
    "    \n",
    "    Parameters:\n",
    "    model - YOLO model used to detect the person in the image.\n",
    "    images (list) - List containing the images to be processed.\n",
    "    confidence_threshold (float) - Confidence threshold to filter out predictions below the threshold.\n",
    "\n",
    "    Returns:\n",
    "    filtered_images (list) - List containing the filtered images.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_images = []\n",
    "    model = YOLO('yolov8n.pt')\n",
    "\n",
    "    for input_image in images:\n",
    "        \n",
    "        try:\n",
    "            # Making predictions\n",
    "            predictions = model.predict(input_image, classes=0)\n",
    "            \n",
    "            for index, i in enumerate(predictions[0].boxes.cls):\n",
    "                # Checking if the image contains a person and if the confidence is above the threshold\n",
    "                if i == 0 and predictions[0].boxes.conf[index] > confidence_threshold: \n",
    "                    filtered_images.append(input_image)\n",
    "                    break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "parquet_file_paths = [\"Datasets\\\\LAION-400M\\\\part-00001-5b54c5d5-bbcf-484d-a2ce-0d6f73df1a36-c000.snappy.parquet\"]\n",
    "labels = [\"doctor\", \"nurse\"]\n",
    "\n",
    "url_dict_1 = LoadLAION_400MImages(parquet_file_paths, labels)\n",
    "docImages, docFailedToGetImageCounter = RetrieveImagesFromLinks(url_dict_1[\"doctor\"])\n",
    "\n",
    "confidence_threshold = 0.75\n",
    "filtered_images = RemoveImageNotContainingPeople(docImages, confidence_threshold)\n",
    "\n",
    "directory_path = \"C:\\\\Users\\\\User\\\\FYP\\\\DownloadedImages\\\\LAION-400M\\\\doctorImageLAION400M-1\"\n",
    "for index, image in enumerate(filtered_images):\n",
    "    cv2.imwrite(os.path.join(directory_path, str(index)+\".jpg\"), cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Snippet 4\n",
    "Description: Code used to move a random number of images from one directory to another.\n",
    " \n",
    "Note: This was used to select the 385 images from the LAION-400M dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: 65.jpg\n",
      "Moved: 2.jpg\n",
      "Moved: 45.jpg\n",
      "Moved: 12.jpg\n",
      "Moved: 123.jpg\n",
      "Moved: 170.jpg\n",
      "Moved: 115.jpg\n",
      "Moved: 179.jpg\n",
      "Moved: 178.jpg\n",
      "Moved: 132.jpg\n",
      "Moved: 81.jpg\n",
      "Moved: 192.jpg\n",
      "Moved: 172.jpg\n",
      "Moved: 84.jpg\n",
      "Moved: 117.jpg\n",
      "Moved: 129.jpg\n",
      "Moved: 79.jpg\n",
      "Moved: 18.jpg\n",
      "Moved: 1.jpg\n",
      "Moved: 21.jpg\n",
      "Moved: 96.jpg\n",
      "Moved: 32.jpg\n",
      "Moved: 38.jpg\n",
      "Moved: 93.jpg\n",
      "Moved: 55.jpg\n",
      "Moved: 35.jpg\n",
      "Moved: 92.jpg\n",
      "Moved: 155.jpg\n",
      "Moved: 27.jpg\n",
      "Moved: 191.jpg\n",
      "Moved: 83.jpg\n",
      "Moved: 133.jpg\n",
      "Moved: 144.jpg\n",
      "Moved: 88.jpg\n",
      "Moved: 143.jpg\n",
      "Moved: 39.jpg\n",
      "Moved: 140.jpg\n",
      "Moved: 151.jpg\n",
      "Moved: 64.jpg\n",
      "Moved: 118.jpg\n",
      "Moved: 128.jpg\n",
      "Moved: 15.jpg\n",
      "Moved: 168.jpg\n",
      "Moved: 94.jpg\n",
      "Moved: 157.jpg\n",
      "Moved: 0.jpg\n",
      "Moved: 40.jpg\n",
      "Moved: 97.jpg\n",
      "Moved: 106.jpg\n",
      "Moved: 48.jpg\n",
      "Moved: 61.jpg\n",
      "Moved: 112.jpg\n",
      "Moved: 153.jpg\n",
      "Moved: 87.jpg\n",
      "Moved: 75.jpg\n",
      "Moved: 67.jpg\n",
      "Moved: 119.jpg\n",
      "Moved: 114.jpg\n",
      "Moved: 8.jpg\n",
      "Moved: 108.jpg\n",
      "Moved: 14.jpg\n",
      "Moved: 131.jpg\n",
      "Moved: 185.jpg\n",
      "Moved: 53.jpg\n",
      "Moved: 186.jpg\n",
      "Moved: 134.jpg\n",
      "Moved: 110.jpg\n",
      "Moved: 166.jpg\n",
      "Moved: 24.jpg\n",
      "Moved: 176.jpg\n",
      "Moved: 34.jpg\n",
      "Moved: 147.jpg\n",
      "Moved: 135.jpg\n",
      "Moved: 56.jpg\n",
      "Moved: 116.jpg\n",
      "Moved: 145.jpg\n",
      "Moved: 169.jpg\n",
      "Moved: 49.jpg\n",
      "Moved: 5.jpg\n",
      "Moved: 127.jpg\n",
      "Moved: 109.jpg\n",
      "Moved: 7.jpg\n",
      "Moved: 85.jpg\n",
      "Moved: 183.jpg\n",
      "Moved: 149.jpg\n",
      "Moved: 68.jpg\n",
      "Moved: 77.jpg\n",
      "Moved: 19.jpg\n",
      "Moved: 16.jpg\n",
      "Moved: 72.jpg\n",
      "Moved: 148.jpg\n",
      "Moved: 189.jpg\n",
      "Moved: 150.jpg\n",
      "Moved: 78.jpg\n",
      "Moved: 51.jpg\n",
      "Moved: 80.jpg\n",
      "Moved: 29.jpg\n",
      "Moved: 187.jpg\n",
      "Moved: 6.jpg\n",
      "Moved: 101.jpg\n",
      "Moved: 62.jpg\n",
      "Moved: 52.jpg\n",
      "Moved: 46.jpg\n",
      "Moved: 136.jpg\n",
      "Moved: 28.jpg\n",
      "Moved: 159.jpg\n",
      "Moved: 9.jpg\n",
      "Moved: 74.jpg\n",
      "Moved: 54.jpg\n",
      "Moved: 181.jpg\n",
      "Moved: 193.jpg\n",
      "Moved: 137.jpg\n",
      "Moved: 113.jpg\n",
      "Moved: 160.jpg\n",
      "Moved: 122.jpg\n",
      "Moved: 141.jpg\n",
      "Moved: 152.jpg\n",
      "Moved: 59.jpg\n",
      "Moved: 33.jpg\n",
      "Moved: 11.jpg\n",
      "Moved: 82.jpg\n",
      "Moved: 163.jpg\n",
      "Moved: 99.jpg\n",
      "Moved: 174.jpg\n",
      "Moved: 69.jpg\n",
      "Moved: 58.jpg\n",
      "Moved: 177.jpg\n",
      "Moved: 70.jpg\n",
      "Moved: 4.jpg\n",
      "Moved: 25.jpg\n",
      "Moved: 98.jpg\n",
      "Moved: 44.jpg\n",
      "Moved: 73.jpg\n",
      "Moved: 63.jpg\n",
      "Moved: 125.jpg\n",
      "Moved: 17.jpg\n",
      "Moved: 158.jpg\n",
      "Moved: 194.jpg\n",
      "Moved: 171.jpg\n",
      "Moved: 104.jpg\n",
      "Moved: 164.jpg\n",
      "Moved: 130.jpg\n",
      "Moved: 13.jpg\n",
      "Moved: 103.jpg\n",
      "Moved: 156.jpg\n",
      "Moved: 175.jpg\n",
      "Moved: 121.jpg\n",
      "Moved: 124.jpg\n",
      "Moved: 41.jpg\n",
      "Moved: 95.jpg\n",
      "Moved: 42.jpg\n",
      "Moved: 47.jpg\n",
      "Moved: 107.jpg\n",
      "Moved: 76.jpg\n",
      "Moved: 102.jpg\n",
      "Moved: 139.jpg\n",
      "Moved: 165.jpg\n",
      "Moved: 37.jpg\n",
      "Moved: 120.jpg\n",
      "Moved: 167.jpg\n",
      "Moved: 105.jpg\n",
      "Moved: 180.jpg\n",
      "Moved: 20.jpg\n",
      "Moved: 90.jpg\n",
      "Moved: 71.jpg\n",
      "Moved: 184.jpg\n",
      "Moved: 31.jpg\n",
      "Moved: 3.jpg\n",
      "Moved: 10.jpg\n",
      "Moved: 86.jpg\n",
      "Moved: 182.jpg\n",
      "Moved: 195.jpg\n",
      "Moved: 36.jpg\n",
      "Moved: 142.jpg\n",
      "Moved: 154.jpg\n",
      "Moved: 162.jpg\n",
      "Moved: 22.jpg\n",
      "Moved: 173.jpg\n",
      "Moved: 26.jpg\n",
      "Moved: 91.jpg\n",
      "Moved: 30.jpg\n",
      "Moved: 161.jpg\n",
      "Moved: 126.jpg\n",
      "Moved: 43.jpg\n",
      "Moved: 23.jpg\n",
      "Moved: 138.jpg\n",
      "Moved: 100.jpg\n",
      "Moved: 111.jpg\n",
      "Moved: 50.jpg\n",
      "Moved: 60.jpg\n",
      "Moved: 190.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def move_random_images(source_dir, destination_dir, num_images_to_move):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This function moves a randomly selected number of images from one directory to another, primarily used for random image selection.\n",
    "\n",
    "    Parameters:\n",
    "    source_dir (str) - The directory containing the images to move\n",
    "    destination_dir (str) - The directory to move the images to\n",
    "    num_images_to_move (int) - The number of images to move\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all files in the source directory\n",
    "    all_images = [f for f in os.listdir(source_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    # Randomly select the specified number of images\n",
    "    selected_images = random.sample(all_images, min(num_images_to_move, len(all_images)))\n",
    "\n",
    "    # Move the selected images to the destination directory\n",
    "    for image in selected_images:\n",
    "        source_path = os.path.join(source_dir, image)\n",
    "        destination_path = os.path.join(destination_dir, image)\n",
    "        shutil.move(source_path, destination_path)\n",
    "        print(f'Moved: {image}')\n",
    "\n",
    "# Replace these paths with your actual source and destination directories\n",
    "source_directory = 'C:\\\\Users\\\\User\\\\FYP\\\\DownloadedImages\\\\LAION-400M\\\\doctorImagesFiltered'\n",
    "destination_directory = 'C:\\\\Users\\\\User\\\\FYP\\DownloadedImages\\\\LAION-400M\\\\doctorImageSubsetsForProcessing\\\\tmp'\n",
    "\n",
    "# Specify the number of images you want to move\n",
    "num_images_to_move = 385\n",
    "\n",
    "# Call the function to move random images\n",
    "move_random_images(source_directory, destination_directory, num_images_to_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Snippet 5\n",
    "Description: Code used to determine which images have only a specified number of people in them and copy those images to another directory.\n",
    "\n",
    "Note: This was used to select the 97 images used for the Google Form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 person, 102.0ms\n",
      "Speed: 4.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 5.0ms preprocess, 93.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 101.0ms\n",
      "Speed: 4.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 5.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 5.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 100.0ms\n",
      "Speed: 5.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 5.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 4.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.7ms\n",
      "Speed: 3.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 3.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 112.0ms\n",
      "Speed: 4.0ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 102.0ms\n",
      "Speed: 5.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 112.0ms\n",
      "Speed: 6.0ms preprocess, 112.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 105.0ms\n",
      "Speed: 4.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 5.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 98.0ms\n",
      "Speed: 4.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 6.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 102.0ms\n",
      "Speed: 4.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 100.0ms\n",
      "Speed: 4.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 107.0ms\n",
      "Speed: 5.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 126.0ms\n",
      "Speed: 4.0ms preprocess, 126.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 98.0ms\n",
      "Speed: 4.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 108.0ms\n",
      "Speed: 5.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 100.0ms\n",
      "Speed: 4.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 102.0ms\n",
      "Speed: 5.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 138.0ms\n",
      "Speed: 5.0ms preprocess, 138.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 104.0ms\n",
      "Speed: 5.0ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 108.0ms\n",
      "Speed: 6.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 100.0ms\n",
      "Speed: 4.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 104.0ms\n",
      "Speed: 4.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 5.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 3.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 5.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 108.0ms\n",
      "Speed: 7.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 107.0ms\n",
      "Speed: 4.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 109.0ms\n",
      "Speed: 5.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 104.0ms\n",
      "Speed: 5.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 104.0ms\n",
      "Speed: 6.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 116.0ms\n",
      "Speed: 5.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 105.0ms\n",
      "Speed: 4.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 105.0ms\n",
      "Speed: 5.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 122.0ms\n",
      "Speed: 5.0ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 106.0ms\n",
      "Speed: 4.0ms preprocess, 106.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 4.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 4.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 103.0ms\n",
      "Speed: 5.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 5.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 5.0ms preprocess, 95.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 6.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 105.0ms\n",
      "Speed: 4.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 5.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 5.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 5.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 112.0ms\n",
      "Speed: 3.0ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 5.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 104.0ms\n",
      "Speed: 4.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 7.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 5.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 5.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 5.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 5.0ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 14.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 106.0ms\n",
      "Speed: 4.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 5.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 107.0ms\n",
      "Speed: 3.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 4.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 5.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 5.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 6.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 5.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 5.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 7.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 14.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 5.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 78.0ms\n",
      "Speed: 4.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 3.0ms preprocess, 94.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 3.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 5.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 5.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 3.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 5.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 5.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 109.0ms\n",
      "Speed: 6.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 5.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 117.0ms\n",
      "Speed: 4.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 100.0ms\n",
      "Speed: 5.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 98.0ms\n",
      "Speed: 4.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 5.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 10.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 5.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 5.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 9.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 4.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 112.0ms\n",
      "Speed: 4.0ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 5.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 93.0ms\n",
      "Speed: 4.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 5.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 5.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 15.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 100.0ms\n",
      "Speed: 4.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 3.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 4.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 5.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 97.0ms\n",
      "Speed: 4.0ms preprocess, 97.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 96.0ms\n",
      "Speed: 4.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 117.0ms\n",
      "Speed: 5.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 88.0ms\n",
      "Speed: 5.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 91.0ms\n",
      "Speed: 5.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 98.0ms\n",
      "Speed: 5.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 86.0ms\n",
      "Speed: 4.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 4.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 89.0ms\n",
      "Speed: 5.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 90.0ms\n",
      "Speed: 4.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 94.0ms\n",
      "Speed: 6.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dlib\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def get_person_images(source_dir, destination_dir, confidence_threshold, number_of_people, num_images_to_move = None):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This function moves all or a randomly selected number of images containing the indicated number of people from one directory to another.\n",
    "\n",
    "    Parameters:\n",
    "    source_dir (str) - The directory containing the images to move\n",
    "    destination_dir (str) - The directory to move the images to\n",
    "    confidence_threshold (float) - The confidence threshold for the YOLO model\n",
    "    number_of_people (int) - The number of people to look for in the images\n",
    "    num_images_to_move (int) - The number of images to move\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a list of all files in the source directory\n",
    "    all_images = [f for f in os.listdir(source_directory) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    # Loading the YOLO model. This is downloaded automatically when run for the first time.\n",
    "    model = YOLO('yolov8n.pt')\n",
    "\n",
    "    # List to store the images containing the specified number of people\n",
    "    person_images = []\n",
    "\n",
    "    # Loop through all images in the source directory\n",
    "    for image in all_images:\n",
    "        # Loading the image\n",
    "        input_image_path = os.path.join(source_dir, image)\n",
    "        image = dlib.load_rgb_image(input_image_path)\n",
    "\n",
    "        # Making predictions\n",
    "        predictions = model.predict(image, classes=0)\n",
    "        scores = predictions[0].boxes.conf\n",
    "\n",
    "        # Filtering out the predictions based on the confidence threshold\n",
    "        filtered_indices = torch.where(scores > confidence_threshold)[0]\n",
    "        if len(filtered_indices) == number_of_people:\n",
    "            person_images.append(image) \n",
    "\n",
    "    # Randomly select the specified number of images\n",
    "    selected_images = person_images if num_images_to_move == None else random.sample(person_images, min(num_images_to_move, len(person_images)))\n",
    "\n",
    "    # Copying the images over to the new directory\n",
    "    for imgIndex, image in enumerate(selected_images):\n",
    "        save_path = destination_dir\n",
    "        save_path = os.path.join(save_path,str(imgIndex)+\".jpg\")\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "source_directory = 'C:\\\\Users\\\\User\\\\FYP\\\\MidJourney\\\\DoctorFinalisedFiltering'   \n",
    "destination_directory = 'C:\\\\Users\\\\User\\\\FYP\\\\MidJourney\\\\tmp' \n",
    "confidence_threshold = 0.5\n",
    "number_of_people = 1\n",
    "num_images = 10\n",
    "\n",
    "get_person_images(source_directory, destination_directory, confidence_threshold, number_of_people, num_images_to_move = num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Snippet 6\n",
    "\n",
    "Description: Code used to load and process the data retrieved from the Google Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female is positively correlated with the image type.  0.6288659793814433  >  0.5\n",
      "white is positively correlated with the image type.  0.6288659793814433  >  0.16666666666666666\n",
      "20-29 is positively correlated with the image type.  0.26804123711340205  >  0.1111111111111111\n",
      "30-39 is positively correlated with the image type.  0.4845360824742268  >  0.1111111111111111\n",
      "40-49 is positively correlated with the image type.  0.18556701030927836  >  0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "# Note: The NAN values in the CSV file are present as those images were annotated by other users. \n",
    "# For instance image 0 was annoted by user 1 & 2 but image 25 was annoted by users 3 & 4 so \n",
    "# image 0 has NaN values for user 3 & 4 and image 25 has NaN values for user 1 & 2.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of files containing the annotations\n",
    "file_paths = [\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 1 (Responses) - Form responses 1.csv\",\n",
    "\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 2 (Responses) - Form responses 1.csv\",\n",
    "\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 3 (Responses) - Form responses 1.csv\",\n",
    "\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 4 (Responses) - Form responses 1.csv\"]\n",
    "\n",
    "# List of files containing the annotations\n",
    "# file_paths = [\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Nurse-97\\\\GoogleFormResponses\\\\Nurse Annotation - 1 (Responses) - Form responses 1.csv\",\n",
    "# \"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Nurse-97\\\\GoogleFormResponses\\\\Nurse Annotation - 2 (Responses) - Form responses 1.csv\",\n",
    "# \"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Nurse-97\\\\GoogleFormResponses\\\\Nurse Annotation - 3 (Responses) - Form responses 1.csv\",\n",
    "# \"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Nurse-97\\\\GoogleFormResponses\\\\Nurse Annotation - 4 (Responses) - Form responses 1.csv\"]\n",
    "\n",
    "def LoadAndProcessGoogleFormData(file_paths):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This function loads the google form csv files, updates their column names and assigns a singular \n",
    "    result per attribute per image entry based on the most common value/averaging.\n",
    "    \n",
    "    Parameters:\n",
    "    file_paths (list) - List containing the distance between the centers of the image and the center of the bounding box in each image.\n",
    "\n",
    "    Returns:\n",
    "    image_set_data (dict) - Dictionary containing the processed data for each image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty DataFrame to store the concatenated data\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Dictionary to store the image data\n",
    "    image_set_data = {}\n",
    "\n",
    "    # Loop through each CSV file and concatenate the DataFrames\n",
    "    for index, csv_file in enumerate(file_paths):\n",
    "        # Read a singular CSV file into a DataFrame\n",
    "        part_df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Changing the column names for easier access\n",
    "        # List of column names\n",
    "        column_names = part_df.keys()\n",
    "\n",
    "        column_mapping = {}\n",
    "        column_mapping[column_names[1]] = \"Gender_User\"\n",
    "        column_mapping[column_names[2]] = \"Race_User\"\n",
    "        column_mapping[column_names[3]] = \"Age_User\"\n",
    "        \n",
    "        # Each file contains 25 images, so the image number is calculated by multiplying the index by 25\n",
    "        image_number = index*25\n",
    "\n",
    "        # Loop through the column names, starting from the 5th column and update the names accroding to the image with which the coencide\n",
    "        for index in range(4,len(column_names),3):\n",
    "            column_mapping[column_names[index]] = \"Gender_\"+str(image_number)\n",
    "            column_mapping[column_names[index+1]] = \"Race_\"+str(image_number)\n",
    "            column_mapping[column_names[index+2]] = \"Age_\"+str(image_number)\n",
    "            image_number += 1\n",
    "\n",
    "        # Rename the columns using the rename method\n",
    "        part_df = part_df.rename(columns=column_mapping)\n",
    "        df = pd.concat([df, part_df], ignore_index=True)\n",
    "\n",
    "    # The number of images is calculated by subtracting 4 (Timestamp/Gender_User/Race_User/Age_User) \n",
    "    # from the total number of columns and then dividing by 3 (Number of labels for each image)\n",
    "    number_of_images = int((len(df.keys())-4)/3)\n",
    "    for image_index in range(0,number_of_images):\n",
    "        image_data = {}\n",
    "        image_data[\"age\"] = list(df[\"Age_\"+str(image_index)].dropna())\n",
    "        image_data[\"gender\"] = list(df[\"Gender_\"+str(image_index)].dropna())\n",
    "        image_data[\"race\"] = list(df[\"Race_\"+str(image_index)].dropna())\n",
    "        image_set_data[image_index] = image_data\n",
    "\n",
    "    for image_index in image_set_data:\n",
    "        age = round(np.mean(image_set_data[image_index][\"age\"]))\n",
    "\n",
    "        if age >= 0 and age <= 2: \n",
    "            age_label = \"0-2\"\n",
    "        elif age >= 3 and age <= 9:\n",
    "            age_label = \"3-9\"\n",
    "        elif age >= 10 and age <= 19:\n",
    "            age_label = \"10-19\"\n",
    "        elif age >= 20 and age <= 29:\n",
    "            age_label = \"20-29\"\n",
    "        elif age >= 30 and age <= 39:\n",
    "            age_label = \"30-39\"\n",
    "        elif age >= 40 and age <= 49:\n",
    "            age_label = \"40-49\"\n",
    "        elif age >= 50 and age <= 59:\n",
    "            age_label = \"50-59\"\n",
    "        elif age >= 60 and age <= 69:\n",
    "            age_label = \"60-69\"\n",
    "        elif age >= 70:\n",
    "            age_label = \"70+\"\n",
    "        \n",
    "        image_set_data[image_index][\"age\"] = age_label\n",
    "        # Takes the most common value otherwise the first value\n",
    "        image_set_data[image_index][\"gender\"] = Counter(image_set_data[image_index][\"gender\"]).most_common(1)[0][0] \n",
    "        image_set_data[image_index][\"race\"] = Counter(image_set_data[image_index][\"race\"]).most_common(1)[0][0]\n",
    "\n",
    "    return image_set_data\n",
    "\n",
    "def DisplayGoogleFormData(image_set_data):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This Function displays the label counts across all images.\n",
    "    \n",
    "    Parameters:\n",
    "    image_set_data (dict) - Dictionary containing the processed data for each image.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the count dictionaries\n",
    "    gender_count = {\"male\":0,\"female\":0}\n",
    "    race_count = {\"white\":0,\"black\":0,\"latino hispanic\":0,\"asian\":0,\"indian\":0,\"middle eastern\":0}\n",
    "    age_count = {\"0-2\":0,\"3-9\":0,\"10-19\":0,\"20-29\":0,\"30-39\":0,\"40-49\":0,\"50-59\":0,\"60-69\":0,\"70+\":0}\n",
    "\n",
    "    # Loop through the image set data and update the mappings\n",
    "    for index in image_set_data: \n",
    "        age_count[image_set_data[index][\"age\"]] += 1\n",
    "        gender_count[image_set_data[index][\"gender\"].lower()] += 1\n",
    "        race_count[image_set_data[index][\"race\"].lower()] += 1\n",
    "\n",
    "    # Plotting gender data\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    bars = plt.bar(gender_count.keys(), gender_count.values())\n",
    "    values = gender_count.values()\n",
    "    plt.title('Gender Distribution')\n",
    "    plt.xlabel('Gender')\n",
    "    plt.ylabel('Count')\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "    # Plotting race data\n",
    "    plt.subplot(1, 3, 2)\n",
    "    bars = plt.bar(race_count.keys(), race_count.values())\n",
    "    values = race_count.values()\n",
    "    plt.title('Race Distribution')\n",
    "    plt.xlabel('Race')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "    # Plotting age data\n",
    "    plt.subplot(1, 3, 3)\n",
    "    bars = plt.bar(age_count.keys(), age_count.values())\n",
    "    values = age_count.values()\n",
    "    plt.title('Age Distribution')\n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Same Function from the main pipeline just altered to function with the google form data.\n",
    "def CorrelationMetric(data):\n",
    "    correlation_gender = {\"male\": 0, \"female\": 0}\n",
    "    correlation_race = {\"asian\": 0, \"white\": 0, \"middle eastern\": 0, \"indian\": 0, \"latino hispanic\": 0, \"black\": 0}\n",
    "    correlation_age = {\"0-2\":0,\"3-9\":0,\"10-19\":0,\"20-29\":0,\"30-39\":0,\"40-49\":0,\"50-59\":0,\"60-69\":0,\"70+\":0}\n",
    "    count = len(data)\n",
    "    dict_list = [correlation_gender, correlation_race, correlation_age]\n",
    "\n",
    "    # Working out the number of each metric present across the set of images\n",
    "    for index in range(len(data)):\n",
    "        correlation_gender[data[index][\"gender\"].lower()] += 1\n",
    "\n",
    "        correlation_race[data[index][\"race\"].lower()] += 1\n",
    "\n",
    "        correlation_age[data[index][\"age\"]] += 1\n",
    "\n",
    "    for dict in dict_list:\n",
    "        for item in dict:\n",
    "            # Divide all values in the dictionary by count\n",
    "            dict[item] /= count\n",
    "            if dict[item] > 1/len(dict):\n",
    "                print(item, \"is positively correlated with the image type. \",dict[item], \" > \", 1/len(dict))\n",
    "\n",
    "image_set_data = LoadAndProcessGoogleFormData(file_paths)\n",
    "DisplayGoogleFormData(image_set_data)\n",
    "CorrelationMetric(image_set_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Snippet 7\n",
    "\n",
    "Description: Code used to work out the Fleiss Kappa valur for the Google Form results.\n",
    "\n",
    "Note: That each annotation csv should have the same number of entries to get the correct results.\n",
    "\n",
    "Fleiss Kappa Interpratation Guide: https://datatab.net/tutorial/fleiss-kappa\n",
    "\n",
    "<table ><tr><th>Kappa</th><th>Level of Agreement</th></tr>\n",
    "<tr><td> &gt 0.8 </td><td> Almost Perfect </td></tr>\n",
    "<tr><td> &gt 0.6 </td><td> Substantial </td></tr>\n",
    "<tr><td> &gt 0.4 </td><td> Moderate </td></tr>\n",
    "<tr><td> &gt 0.2 </td><td> Fair </td></tr>\n",
    "<tr><td> &gt 0 </td><td> Slight </td></tr>\n",
    "<tr><td> &lt 0 </td><td> No Agreement </td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def FleissKappa(file_paths):\n",
    "    \"\"\" \n",
    "    Description:\n",
    "    This function calculates the Fleiss Kappa for the image set data.\n",
    "    \n",
    "    Parameters:\n",
    "    image_set_data (dict) - Dictionary containing the processed data for each image.\n",
    "\n",
    "    Returns:\n",
    "    k_values (dict) - Dictionary containing the Fleiss Kappa values for each attribute.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty DataFrame to store the concatenated data\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Dictionary to store the image data\n",
    "    image_set_data = {}\n",
    "\n",
    "    # Loop through each CSV file and concatenate the DataFrames\n",
    "    for index, csv_file in enumerate(file_paths):\n",
    "        # Read a singular CSV file into a DataFrame\n",
    "        part_df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Changing the column names for easier access\n",
    "        # List of column names\n",
    "        column_names = part_df.keys()\n",
    "\n",
    "        column_mapping = {}\n",
    "        column_mapping[column_names[1]] = \"Gender_User\"\n",
    "        column_mapping[column_names[2]] = \"Race_User\"\n",
    "        column_mapping[column_names[3]] = \"Age_User\"\n",
    "        \n",
    "        # Each file contains 25 images, so the image number is calculated by multiplying the index by 25\n",
    "        image_number = index*25\n",
    "\n",
    "        # Loop through the column names, starting from the 5th column and update the names accroding to the image with which the coencide\n",
    "        for index in range(4,len(column_names),3):\n",
    "            column_mapping[column_names[index]] = \"Gender_\"+str(image_number)\n",
    "            column_mapping[column_names[index+1]] = \"Race_\"+str(image_number)\n",
    "            column_mapping[column_names[index+2]] = \"Age_\"+str(image_number)\n",
    "            image_number += 1\n",
    "\n",
    "        # Rename the columns using the rename method\n",
    "        part_df = part_df.rename(columns=column_mapping)\n",
    "        df = pd.concat([df, part_df], ignore_index=True)\n",
    "\n",
    "    # The number of images is calculated by subtracting 4 (Timestamp/Gender_User/Race_User/Age_User) \n",
    "    # from the total number of columns and then dividing by 3 (Number of labels for each image)\n",
    "    number_of_images = int((len(df.keys())-4)/3)\n",
    "    for image_index in range(0,number_of_images):\n",
    "        image_data = {}\n",
    "        image_data[\"age\"] = list(df[\"Age_\"+str(image_index)].dropna())\n",
    "        image_data[\"gender\"] = list(df[\"Gender_\"+str(image_index)].dropna())\n",
    "        image_data[\"race\"] = list(df[\"Race_\"+str(image_index)].dropna())\n",
    "        image_set_data[image_index] = image_data\n",
    "    #----------------------------------------\n",
    "\n",
    "    observed_agreement = {\"gender\":0, \"race\":0, \"age\":0, \"age-ranges\":0}\n",
    "    expected_agreement = {\"gender\":0, \"race\":0, \"age\":0, \"age-ranges\":0}\n",
    "\n",
    "    # These dictionaries store the counts of each attribute for each image\n",
    "    gender_count = {\"male\":0,\"female\":0}\n",
    "    race_count = {\"white\":0,\"black\":0,\"latino hispanic\":0,\"asian\":0,\"indian\":0,\"middle eastern\":0}\n",
    "    age_ranges_count = {\"0-2\":0,\"3-9\":0,\"10-19\":0,\"20-29\":0,\"30-39\":0,\"40-49\":0,\"50-59\":0,\"60-69\":0,\"70+\":0}\n",
    "    age_count = {}\n",
    "    \n",
    "    # Populate the dictionary with keys ranging from 0 to 100, each with a value of 0\n",
    "    for i in range(101):\n",
    "        age_count[i] = 0\n",
    "\n",
    "    individual_image_data = {}\n",
    "\n",
    "    number_of_images_N = len(image_set_data)\n",
    "    number_of_annottors_n = len(image_set_data[0][\"gender\"])\n",
    "\n",
    "    # Looping through the image set\n",
    "    for index in image_set_data:    \n",
    "        # These dictionaries store the counts of each attribute for each image\n",
    "        individual_image_gender_count = {\"male\":0,\"female\":0}\n",
    "        individual_image_race_count = {\"white\":0,\"black\":0,\"latino hispanic\":0,\"asian\":0,\"indian\":0,\"middle eastern\":0}\n",
    "        individual_image_age_range_count = {\"0-2\":0,\"3-9\":0,\"10-19\":0,\"20-29\":0,\"30-39\":0,\"40-49\":0,\"50-59\":0,\"60-69\":0,\"70+\":0}\n",
    "        individual_image_age_count = {}\n",
    "        \n",
    "        # Populate the dictionary with keys ranging from 0 to 100, each with a value of 0\n",
    "        for i in range(101):\n",
    "            individual_image_age_count[i] = 0\n",
    "\n",
    "        # Working out the counts for each attribute (total and individual attribute counts)\n",
    "        for gender in image_set_data[index][\"gender\"]:\n",
    "            gender_count[gender.lower()] += 1\n",
    "            individual_image_gender_count[gender.lower()] += 1\n",
    "        \n",
    "        # Working out the counts for each attribute (total and individual attribute counts)\n",
    "        for race in image_set_data[index][\"race\"]:\n",
    "            race_count[race.lower()] += 1\n",
    "            individual_image_race_count[race.lower()] += 1\n",
    "\n",
    "        # Working out the counts for each attribute (total and individual attribute counts) \n",
    "        # This is done for the actual age and age ranges \n",
    "        for age in image_set_data[index][\"age\"]:\n",
    "            age_count[int(age)] += 1\n",
    "            individual_image_age_count[int(age)] += 1\n",
    "            \n",
    "            # Working out the age ranges counts\n",
    "            if age >= 0 and age <= 2: \n",
    "                individual_image_age_range_count[\"0-2\"] += 1\n",
    "                age_ranges_count[\"0-2\"] += 1\n",
    "            elif age >= 3 and age <= 9:\n",
    "                individual_image_age_range_count[\"3-9\"] += 1\n",
    "                age_ranges_count[\"3-9\"] += 1\n",
    "            elif age >= 10 and age <= 19:\n",
    "                individual_image_age_range_count[\"10-19\"] += 1\n",
    "                age_ranges_count[\"10-19\"] += 1\n",
    "            elif age >= 20 and age <= 29:\n",
    "                individual_image_age_range_count[\"20-29\"] += 1\n",
    "                age_ranges_count[\"20-29\"] += 1\n",
    "            elif age >= 30 and age <= 39:\n",
    "                individual_image_age_range_count[\"30-39\"] += 1\n",
    "                age_ranges_count[\"30-39\"] += 1\n",
    "            elif age >= 40 and age <= 49:\n",
    "                individual_image_age_range_count[\"40-49\"] += 1\n",
    "                age_ranges_count[\"40-49\"] += 1\n",
    "            elif age >= 50 and age <= 59:\n",
    "                individual_image_age_range_count[\"50-59\"] += 1\n",
    "                age_ranges_count[\"50-59\"] += 1\n",
    "            elif age >= 60 and age <= 69:\n",
    "                individual_image_age_range_count[\"60-69\"] += 1\n",
    "                age_ranges_count[\"60-69\"] += 1\n",
    "            elif age >= 70:\n",
    "                individual_image_age_range_count[\"70+\"] += 1\n",
    "                age_ranges_count[\"70+\"] += 1\n",
    "\n",
    "        # Storing the individual image count data\n",
    "        individual_image_data[index] = {\"gender\":individual_image_gender_count,\"race\": individual_image_race_count,\"age\": individual_image_age_count, \"age-ranges\": individual_image_age_range_count}\n",
    "\n",
    "    # Storing the total image count data\n",
    "    total_count = {\"gender\":gender_count,\"race\": race_count,\"age\": age_count, \"age-ranges\": age_ranges_count}\n",
    "\n",
    "    for label in expected_agreement.keys():\n",
    "        p_e = 0\n",
    "\n",
    "        # Calculating the number of total annotations\n",
    "        total = sum(list(total_count[label.lower()].values()))\n",
    "        # Calculating the expected agreement\n",
    "        for value in total_count[label.lower()].values():\n",
    "            p_e += (value/total)**2\n",
    "        expected_agreement[label] = p_e\n",
    "\n",
    "    part_1 = 1/(number_of_images_N*number_of_annottors_n*(number_of_annottors_n-1))\n",
    "\n",
    "    k_values = {}\n",
    "\n",
    "    for label in observed_agreement.keys():\n",
    "        square_sum = 0\n",
    "        \n",
    "        for index in individual_image_data:\n",
    "            square_sum += sum([x**2 for x in individual_image_data[index][label].values()])\n",
    "        \n",
    "        square_sum -= (number_of_images_N * number_of_annottors_n)\n",
    "        observed_agreement[label] = part_1 * square_sum\n",
    "        k_values[label] = (observed_agreement[label] - expected_agreement[label])/(1-expected_agreement[label])\n",
    "    \n",
    "    print(\"FK Gender \",k_values[\"gender\"],\" FK Race \",k_values[\"race\"],\" FK Age \",k_values[\"age\"],\" FK Age Ranges\",k_values[\"age-ranges\"])\n",
    "    return k_values\n",
    "\n",
    "# List of files containing the annotations\n",
    "file_paths = [\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 1 (Responses) - Form responses 1.csv\",\n",
    "\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 2 (Responses) - Form responses 1.csv\",\n",
    "\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 3 (Responses) - Form responses 1.csv\",\n",
    "\"..\\\\DownloadedImages\\\\LAION-400M-GoogleForm-Images\\\\Doctor-97\\\\GoogleFormResponses\\\\Doctor Annotation - 4 (Responses) - Form responses 1.csv\"]\n",
    "\n",
    "tmp = FleissKappa(file_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
