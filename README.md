# Investigation of Visual Bias in Generative AI

### Authors:
Jerome Agius 

### Supervisors:
Dr Dylan Seychell - Supervisor 

Prof. John Abela - Co Supervisor

## Abstract 
<div align="justify"> 
In the realm of Artificial Intelligence (AI), the emergence of text‐to‐image generators,
such as Stable Diffusion, Dall‐E‐3 and Midjourney has brought about new avenues for
creativity. However, as with any innovation concerns have been raised in regards to
the presence of bias within images generated by such means, particularly those
depicting individuals.

This, thesis explored and analysed the biases within such models by conducting
a comparative analysis between the aforementioned models alongside the publicly
available LAION‐400M training dataset in relation to real‐world bias.

The research approach revolved around the retrieval or generation of images
coinciding with the biased terms doctor and nurse. These terms were used to leverage
real‐world biases throughout the bias identification process thereby exposing how
each generative model deals with this innate bias and by extension discover any bias
mitigation techniques along with their effectiveness in comparison to the other models.

This was achieved by annotating the images using feature extraction models in
particular DeepFace and FairFace, whose accuracy was evaluated on a human
annotated subset of LAION‐400M images. Furthermore, the bias present within the
images was concluded due to a series of metrics particularly gender, race and age
distribution, person prominence along with Shannon and Simpson diversity/evenness
measures. This research highlighted the bias present within the LAION‐400M dataset
along with the Stable Diffusion and Midjourney models whilst outlining the inverse bias
within the Dall‐E model and the effectiveness of its bias mitigation process.

The findings of this research shed light on the pervasiveness of bias in
generative AI, highlighting the urgent need for proactive mitigation strategies whilst
contributing to the understanding of bias and the development of fairer models and
datasets.
</div>

## Repository Content 

* [Thesis](../main/FYP-Paper.pdf) - This is the paper covering the research.
* [VIVA Presentation](../main/VIVA-Presentation.pdf) - This is the presentation used for the VIVA.
* [Thesis Poster](../main/FYP-Poster.pdf) - This is the poster presented during the exhibition.
* [FYP - Pipeline](../main/Executables/FYP-FullPipeline.ipynb) - This contains the main code associated with the research.
* [FYP - Extra Functions](../main/Executables/ExtraFunctions.ipynb) - This contains extra code not directly assocaited with the research.
* [Images](../main/Images/) - The directory contains the images used throughout the research paper. The **DeepFaceImagesMetrics** & **FairFaceImagesMetrics** subdirectories contain the cropped faces of all the images alongside the extracted DeepFace and FairFace metrics. 

<hr>

<p align="center">
  <img src="../main/University-of-Malta.png" alt="University Logo" width="200"/>
</p>

